{
  "id": "04",
  "title": "Lesson 04: Single-layer Networks: Regression",
  "lesson_title": "Single-layer Networks: Regression",
  "objectives": [
    "Understand linear regression as a single-layer neural network",
    "Learn basis functions and feature extraction",
    "Master maximum likelihood for regression",
    "Understand the bias-variance trade-off",
    "Learn decision theory for regression",
    "Understand regularization and weight decay"
  ],
  "cards": [
    {
      "uid": "deep-learning-foundations-and-concepts-04-001",
      "front": "What is the goal of regression?",
      "back": "To predict the value of one or more <b>continuous target variables</b> \\( t \\) given the value of a D-dimensional vector \\( \\vec{x} \\) of input variables.",
      "tags": [
        "ch04",
        "regression",
        "basics"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-002",
      "front": "What is the bias parameter in a linear regression model?",
      "back": "The parameter \\( w_0 \\) that allows for any fixed offset in the data:<br>\\( y(\\vec{x}, \\vec{w}) = w_0 + w_1 x_1 + \\ldots + w_D x_D \\)<br>Also called the intercept. Not to be confused with statistical bias.",
      "tags": [
        "ch04",
        "regression",
        "parameters"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-004",
      "front": "How can a polynomial regression model be expressed using basis functions?",
      "back": "For a single input variable \\( x \\), use basis functions:<br>\\( \\phi_j(x) = x^j \\)<br>So:<br>\\( y(x, \\vec{w}) = w_0 + w_1 x + w_2 x^2 + \\ldots = \\sum_{j=0}^{M-1} w_j x^j \\)",
      "tags": [
        "ch04",
        "polynomial",
        "basis-functions"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-005",
      "front": "Why are models of the form \\( y(\\vec{x}, \\vec{w}) = \\sum_j w_j \\phi_j(\\vec{x}) \\) called linear models?",
      "back": "Because they are <b>linear in the parameters</b> \\( \\vec{w} \\), even though they can be nonlinear in the inputs \\( \\vec{x} \\) (via the basis functions \\( \\phi_j \\)).<br>This linearity in parameters greatly simplifies the analysis.",
      "tags": [
        "ch04",
        "linear-models",
        "basis-functions"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-006",
      "front": "What is least-squares regression?",
      "back": "A method to find parameters by minimizing the <b>sum-of-squares error function</b>:<br>\\( E_D(\\vec{w}) = \\frac{1}{2} \\sum_{n=1}^{N} \\{t_n - \\vec{w}^T \\phi(\\vec{x}_n)\\}^2 \\)<br>Equivalent to maximum likelihood under Gaussian noise assumption.",
      "tags": [
        "ch04",
        "least-squares",
        "optimization"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-007",
      "front": "Why is maximizing likelihood under Gaussian noise equivalent to minimizing sum-of-squares error?",
      "back": "The log likelihood under Gaussian noise is:<br>\\( \\ln p(\\mathbf{t}|X, \\vec{w}, \\sigma^2) = -\\frac{N}{2}\\ln\\sigma^2 - \\frac{N}{2}\\ln(2\\pi) - \\frac{1}{\\sigma^2}E_D(\\vec{w}) \\)<br>The first two terms are constants w.r.t. \\( \\vec{w} \\), so maximizing likelihood is equivalent to minimizing \\( E_D(\\vec{w}) \\).",
      "tags": [
        "ch04",
        "maximum-likelihood",
        "least-squares"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-008",
      "front": "What are the normal equations for least-squares regression?",
      "back": "The closed-form solution for \\( \\vec{w} \\):<br>\\( \\vec{w}_{ML} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf{t} \\)<br>Where \\( \\Phi \\) is the design matrix with elements \\( \\Phi_{nj} = \\phi_j(\\vec{x}_n) \\).",
      "tags": [
        "ch04",
        "normal-equations",
        "least-squares"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-009",
      "front": "What is the Moore-Penrose pseudo-inverse?",
      "back": "A generalization of matrix inverse to non-square matrices:<br>\\( \\Phi^\\dagger = (\\Phi^T \\Phi)^{-1} \\Phi^T \\)<br>Used in the normal equations: \\( \\vec{w}_{ML} = \\Phi^\\dagger \\mathbf{t} \\)<br>If \\( \\Phi \\) is square and invertible, \\( \\Phi^\\dagger = \\Phi^{-1} \\).",
      "tags": [
        "ch04",
        "pseudo-inverse",
        "linear-algebra"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-010",
      "front": "What is a batch method in machine learning?",
      "back": "A method where the <b>entire training data set is processed at once</b> to update parameters.<br>Contrast with sequential/online methods that process data points one at a time.",
      "tags": [
        "ch04",
        "batch-learning",
        "training"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-011",
      "front": "What are sequential algorithms (online algorithms)?",
      "back": "Algorithms that process data points <b>one at a time</b> and then discard them.<br>Important for:<br><ul><li>Online applications</li><li>Large datasets where batch processing is infeasible</li></ul>Also called online algorithms.",
      "tags": [
        "ch04",
        "online-learning",
        "sequential"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-013",
      "front": "What is the LMS (least-mean-squares) algorithm?",
      "back": "The application of stochastic gradient descent to the sum-of-squares error function:<br>\\( \\vec{w}^{(\\tau+1)} = \\vec{w}^{(\\tau)} + \\eta(t_n - \\vec{w}^{(\\tau)T}\\phi_n)\\phi_n \\)<br>A classic sequential learning algorithm for linear regression.",
      "tags": [
        "ch04",
        "lms",
        "sgd"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-014",
      "front": "What is the simplest form of regularizer in regression?",
      "back": "The sum of squares of the weight vector elements (L2 regularization):<br>\\( E_W(\\vec{w}) = \\frac{1}{2}\\vec{w}^T\\vec{w} = \\frac{1}{2}\\|\\vec{w}\\|^2 \\)<br>Total error: \\( E(\\vec{w}) = E_D(\\vec{w}) + \\lambda E_W(\\vec{w}) \\)<br>Also called <b>parameter shrinkage</b> or <b>weight decay</b>.",
      "tags": [
        "ch04",
        "regularization",
        "weight-decay"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-015",
      "front": "What are the two stages in solving a regression problem using probabilistic methods?",
      "back": "<ol><li><b>Inference stage</b>: Learn a model for the predictive distribution \\( p(t|\\vec{x}) \\) from training data</li><li><b>Decision stage</b>: Use the predictive distribution to make predictions, minimizing a loss function</li></ol>This separation is a key principle of decision theory.",
      "tags": [
        "ch04",
        "decision-theory",
        "inference"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-016",
      "front": "What is a loss function in regression?",
      "back": "A function that quantifies the penalty for predicting \\( f(\\vec{x}) \\) when the true value is \\( t \\):<br>\\( L(t, f(\\vec{x})) \\)<br>The goal is to choose \\( f \\) to minimize the <b>expected loss</b> under the predictive distribution.",
      "tags": [
        "ch04",
        "loss-function",
        "decision-theory"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-018",
      "front": "What is the optimal prediction under squared loss?",
      "back": "The <b>conditional mean</b> (regression function):<br>\\( f^*(\\vec{x}) = E[t|\\vec{x}] = \\int t \\, p(t|\\vec{x}) \\, dt \\)<br>This minimizes the expected squared loss:<br>\\( E[L] = \\int\\int \\{f(\\vec{x}) - t\\}^2 p(\\vec{x}, t) \\, d\\vec{x} \\, dt \\)",
      "tags": [
        "ch04",
        "regression-function",
        "squared-loss"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-019",
      "front": "How can you determine a suitable value for the regularization coefficient \\( \\lambda \\)?",
      "back": "Methods include:<br><ul><li><b>Validation set</b>: Hold out data to evaluate different \\( \\lambda \\) values</li><li><b>Cross-validation</b>: K-fold validation to estimate generalization error</li><li><b>Bayesian methods</b>: Place a prior on \\( \\lambda \\) and marginalize</li></ul>The optimal \\( \\lambda \\) balances bias and variance.",
      "tags": [
        "ch04",
        "regularization",
        "model-selection"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-020",
      "front": "What is the bias-variance trade-off?",
      "back": "<b>Bias</b>: How far off the average prediction is from the truth (systematic error).<br><b>Variance</b>: How much predictions change across different training sets (sensitivity to data).<br><b>Trade-off</b>:<br>\\( \\text{Expected loss} = (\\text{bias})^2 + \\text{variance} + \\text{noise} \\)<br><ul><li>Flexible models: low bias, high variance (overfit)</li><li>Simple models: high bias, low variance (underfit)</li></ul>Optimal complexity balances these.",
      "tags": [
        "ch04",
        "bias-variance",
        "model-selection"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-021",
      "front": "What is the squared bias in the bias-variance decomposition?",
      "back": "The extent to which the <b>average prediction</b> over all possible datasets differs from the true value:<br>\\( (\\text{bias})^2 = \\{E_D[f(\\vec{x}; D)] - h(\\vec{x})\\}^2 \\)<br>Where \\( h(\\vec{x}) \\) is the true underlying function.",
      "tags": [
        "ch04",
        "bias-variance",
        "bias"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-022",
      "front": "What is the variance in the bias-variance decomposition?",
      "back": "The extent to which solutions for individual datasets vary around their average:<br>\\( \\text{variance} = E_D[\\{f(\\vec{x}; D) - E_D[f(\\vec{x}; D)]\\}^2] \\)<br>Measures sensitivity to the particular training set used.",
      "tags": [
        "ch04",
        "bias-variance",
        "variance"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-023",
      "front": "Why does the bias-variance decomposition have limited practical value?",
      "back": "Because it is based on <b>averages with respect to ensembles of datasets</b>.<br>In practice, we have only a single dataset, so we cannot directly measure these quantities.<br>Useful conceptually but hard to apply directly.",
      "tags": [
        "ch04",
        "bias-variance",
        "limitations"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-024",
      "front": "Does overfitting arise in Bayesian settings?",
      "back": "<b>No</b> - overfitting does not arise when we marginalize over parameters in a Bayesian setting.<br>The Bayesian approach integrates over the posterior distribution of parameters rather than using a single point estimate, naturally incorporating uncertainty.",
      "tags": [
        "ch04",
        "overfitting",
        "bayesian"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-025",
      "front": "How can averaging help with the bias-variance trade-off?",
      "back": "Averaging predictions from multiple models can reduce variance without increasing bias.<br>This is the basis for <b>ensemble methods</b> like:<br><ul><li>Bagging</li><li>Random forests</li><li>Model averaging</li></ul>Combines multiple high-variance models to get lower variance.",
      "tags": [
        "ch04",
        "ensemble",
        "averaging"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-026",
      "front": "What is a decision region in classification?",
      "back": "A region of input space where all points are assigned to the same class.<br>The input space is divided into decision regions \\( R_k \\) for each class \\( C_k \\).",
      "tags": [
        "ch04",
        "classification",
        "decision-regions"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-027",
      "front": "What are decision boundaries (decision surfaces)?",
      "back": "The boundaries between decision regions.<br>For a linear discriminant: the hyperplane where \\( y(\\vec{x}) = 0 \\), i.e., \\( \\vec{w}^T\\vec{x} + w_0 = 0 \\).",
      "tags": [
        "ch04",
        "classification",
        "decision-boundaries"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-028",
      "front": "What does it mean for data to be linearly separable?",
      "back": "Data from different classes can be separated by a linear decision boundary (hyperplane).<br>If classes overlap, they are not linearly separable.",
      "tags": [
        "ch04",
        "classification",
        "linear-separability"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-029",
      "front": "What is a discriminant function?",
      "back": "A function that takes an input vector \\( \\vec{x} \\) and assigns it directly to one of K classes.<br>Simplest form for two classes:<br>\\( y(\\vec{x}) = \\vec{w}^T\\vec{x} + w_0 \\)<br>Classify as \\( C_1 \\) if \\( y(\\vec{x}) > 0 \\), else \\( C_2 \\).",
      "tags": [
        "ch04",
        "classification",
        "discriminant"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-030",
      "front": "What is the geometric interpretation of the weight vector in a linear discriminant?",
      "back": "The weight vector \\( \\vec{w} \\) is <b>orthogonal to the decision surface</b>.<br>The bias \\( w_0 \\) determines the <b>location</b> of the decision surface (its distance from the origin).",
      "tags": [
        "ch04",
        "classification",
        "geometry"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-031",
      "front": "What is a one-versus-the-rest classifier?",
      "back": "For K classes, train K binary classifiers, each separating one class from all others combined.<br>Problem: Can lead to ambiguous regions where multiple classifiers claim the point, or no classifier claims it.",
      "tags": [
        "ch04",
        "multi-class",
        "classification"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-032",
      "front": "What is a one-versus-one classifier?",
      "back": "For K classes, train \\( K(K-1)/2 \\) binary classifiers for every pair of classes.<br>Requires more classifiers than one-versus-the-rest but can still lead to ambiguous regions.",
      "tags": [
        "ch04",
        "multi-class",
        "classification"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-033",
      "front": "For K-class linear discriminants, what shape are the decision regions?",
      "back": "The decision regions are always <b>singly connected and convex</b>.<br>This follows from the linearity of the discriminant functions.",
      "tags": [
        "ch04",
        "classification",
        "decision-regions"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-034",
      "front": "What is a discriminative probabilistic model?",
      "back": "A model that directly models the posterior probability \\( p(C_k|\\vec{x}) \\) without modeling the class-conditional densities.<br>Examples: Logistic regression, neural network classifiers.<br>Contrast with generative models.",
      "tags": [
        "ch04",
        "discriminative",
        "probabilistic"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-035",
      "front": "What is a generative probabilistic model?",
      "back": "A model that computes posterior probabilities using Bayes' theorem by modeling:<br><ul><li>Class-conditional densities \\( p(\\vec{x}|C_k) \\)</li><li>Prior probabilities \\( p(C_k) \\)</li></ul>Then uses: \\( p(C_k|\\vec{x}) = \\frac{p(\\vec{x}|C_k)p(C_k)}{p(\\vec{x})} \\)<br>Also models the input distribution \\( p(\\vec{x}) \\).",
      "tags": [
        "ch04",
        "generative",
        "probabilistic"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-036",
      "front": "Why is least-squares sensitive to outliers?",
      "back": "Because the squared error heavily penalizes large deviations.<br>Outliers produce large residuals that disproportionately influence the solution.<br>Techniques sensitive to a few data points are said to <b>lack robustness</b>.",
      "tags": [
        "ch04",
        "least-squares",
        "robustness"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-038",
      "front": "What is the naive Bayes model?",
      "back": "A generative model that assumes <b>conditional independence</b> of features given the class.<br><br><b>Intuition</b>: Imagine classifying emails as spam. Naive Bayes assumes that given an email is spam, the presence of the word 'free' is independent of the word 'money' - each word contributes evidence independently. This is 'naive' because words often <i>do</i> correlate, but the simplification works surprisingly well.<br><br><b>Formula</b>: \\( p(\\vec{x}|C_k) = \\prod_i p(x_i|C_k) \\)<br><br><b>Why it works</b>: Even if independence is violated, the model often ranks classes correctly. We only need the <i>most probable</i> class, not accurate probabilities.",
      "tags": [
        "ch04",
        "naive-bayes",
        "generative"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-039",
      "front": "What is the confusion matrix in classification?",
      "back": "A table showing prediction outcomes:<br>|  | Predicted + | Predicted - |<br>|--|-------------|-------------|<br>| Actual + | True Positive (TP) | False Negative (FN) |<br>| Actual - | False Positive (FP) | True Negative (TN) |<br>False positives = Type 1 errors<br>False negatives = Type 2 errors",
      "tags": [
        "ch04",
        "confusion-matrix",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-040",
      "front": "Why can accuracy be misleading for imbalanced classes?",
      "back": "With strongly imbalanced classes, a naive classifier that always predicts the majority class can achieve high accuracy.<br>Example: 99% negative class - predicting all negative gives 99% accuracy but is useless.<br>Need metrics like precision, recall, F-score instead.",
      "tags": [
        "ch04",
        "accuracy",
        "imbalanced-classes"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-041",
      "front": "What is precision in classification?",
      "back": "The fraction of positive predictions that are correct:<br>\\( \\text{Precision} = \\frac{TP}{TP + FP} \\)<br>Represents the probability that a positive prediction is actually positive.<br>Also called Positive Predictive Value (PPV).",
      "tags": [
        "ch04",
        "precision",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-042",
      "front": "What is recall in classification?",
      "back": "The fraction of actual positives that are correctly identified:<br>\\( \\text{Recall} = \\frac{TP}{TP + FN} \\)<br>Also called sensitivity or True Positive Rate (TPR).",
      "tags": [
        "ch04",
        "recall",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-043",
      "front": "What is the false positive rate (FPR)?",
      "back": "The fraction of actual negatives that are incorrectly classified as positive:<br>\\( \\text{FPR} = \\frac{FP}{FP + TN} \\)<br>Also called the fall-out rate. Used in ROC curves.",
      "tags": [
        "ch04",
        "fpr",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-044",
      "front": "What is the false discovery rate (FDR)?",
      "back": "The fraction of positive predictions that are incorrect:<br>\\( \\text{FDR} = \\frac{FP}{FP + TP} = 1 - \\text{Precision} \\)<br>The complement of precision.",
      "tags": [
        "ch04",
        "fdr",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-045",
      "front": "What is an ROC curve?",
      "back": "<b>Receiver Operating Characteristic</b> curve: a plot of True Positive Rate vs False Positive Rate as the classification threshold varies.<br>Each point represents a different threshold, giving a different confusion matrix.<br>Useful for comparing classifiers and choosing operating points.",
      "tags": [
        "ch04",
        "roc",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-046",
      "front": "What does a classifier below the diagonal mean on an ROC curve?",
      "back": "It performs <b>worse than random guessing</b>.<br>The diagonal represents random classification.<br>Above diagonal = better than random.<br>Perfect classifier = top-left corner (TPR=1, FPR=0).",
      "tags": [
        "ch04",
        "roc",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-047",
      "front": "What is AUC (Area Under the ROC Curve)?",
      "back": "A summary measure of classifier performance:<br><ul><li>AUC = 0.5: Random guessing</li><li>AUC = 1.0: Perfect classifier</li></ul>Represents the probability that a randomly chosen positive example ranks higher than a randomly chosen negative example.",
      "tags": [
        "ch04",
        "auc",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-047a",
      "front": "What is plotted on the x-axis and y-axis of a ROC curve?",
      "back": "<b>X-axis</b>: False Positive Rate (FPR) = FP / (FP + TN)<br><b>Y-axis</b>: True Positive Rate (TPR) = TP / (TP + FN)<br><br><b>Intuition</b>:<ul><li>X-axis: Of all actual negatives, what fraction did we incorrectly call positive?</li><li>Y-axis: Of all actual positives, what fraction did we correctly identify?</li></ul><b>Ideal point</b>: Top-left corner (0, 1) - zero false positives, all true positives detected.",
      "tags": [
        "ch04",
        "roc",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-047b",
      "front": "How do you 'read' the ROC curve and what information does it tell you?",
      "back": "The ROC curve plots <b>false positive rate</b> (x-axis) vs <b>true positive rate</b> (y-axis) for a range of thresholds.<br><br><b>Why thresholds matter</b>: Classifiers usually output a continuous score rather than a binary decision. You must choose a threshold to binarize this score before computing classification metrics.<br><br><b>The trade-off</b>: Raising or lowering the threshold directly trades off between TPR and FPR:<ul><li>Lower threshold: More positives predicted → higher TPR but also higher FPR</li><li>Higher threshold: Fewer positives predicted → lower FPR but also lower TPR</li></ul><b>Reading the curve</b>: The ROC curve shows this entire trade-off. The <b>area under the curve (AUC)</b> measures how 'nice' this trade-off is - a larger area means the classifier can achieve high TPR without incurring high FPR.",
      "tags": [
        "ch04",
        "roc",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-048",
      "front": "What is the F-score?",
      "back": "The harmonic mean of precision and recall:<br>\\( F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\)<br>Balances precision and recall. The general \\( F_\\beta \\) score weights recall \\( \\beta \\) times as much as precision.",
      "tags": [
        "ch04",
        "f-score",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-049",
      "front": "What is the reject option in classification?",
      "back": "Refusing to classify inputs where the classifier is uncertain.<br>Implemented by introducing a threshold \\( \\theta \\) and rejecting inputs where the largest posterior probability \\( \\max_k p(C_k|\\vec{x}) < \\theta \\).<br>Reduces errors at the cost of leaving some inputs unclassified.",
      "tags": [
        "ch04",
        "reject-option",
        "classification"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-050",
      "front": "What are four reasons to compute posterior probabilities even if you just need class predictions?",
      "back": "<ol><li><b>Minimizing risk</b>: Incorporate different misclassification costs</li><li><b>Reject option</b>: Refuse uncertain predictions</li><li><b>Compensating for class priors</b>: Adjust for different train/test class distributions</li><li><b>Combining models</b>: Properly combine predictions from multiple models</li></ol>",
      "tags": [
        "ch04",
        "posterior",
        "decision-theory"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-051",
      "front": "What is outlier detection (novelty detection)?",
      "back": "Identifying inputs that differ significantly from the training data.<br>Important when test data may contain examples from classes not seen during training.<br>Generative models are naturally suited for this since they model \\( p(\\vec{x}) \\).",
      "tags": [
        "ch04",
        "outlier-detection",
        "novelty-detection"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-052",
      "front": "What is a precision-recall (PR) curve?",
      "back": "A <b>precision-recall curve</b> plots <b>precision</b> vs <b>recall</b> as the classification threshold varies.<br><br>Each threshold gives a different confusion matrix, hence different precision/recall.<br><br>PR curves are especially informative when the <b>positive class is rare</b>.<br><br><b>Intuition</b>: With rare positives (e.g., 1% fraud), a bad classifier predicting 'always negative' gets 99% accuracy and low FPR (few false positives relative to many true negatives). ROC curves, which use FPR, can look deceptively good. But precision asks: 'Of predicted positives, how many are correct?' This exposes the failure - if you never predict positive, precision is undefined; if you predict a few, precision will be low because true positives are so rare. PR curves focus entirely on the positive class, ignoring the overwhelming true negatives that mask poor performance.",
      "tags": [
        "ch04",
        "precision-recall",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-053",
      "front": "What is PR-AUC (area under the precision-recall curve)?",
      "back": "<b>PR-AUC</b> summarizes a PR curve as a single number (area under the curve).<br><br><b>Baseline</b>: A random classifier has precision equal to the positive class prevalence \\( p(y=1) \\), so the baseline PR curve is a horizontal line at that value.<br><br>Higher PR-AUC indicates better performance on the positive class.",
      "tags": [
        "ch04",
        "pr-auc",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-055",
      "front": "What does it mean for a classifier to be well-calibrated?",
      "back": "A classifier is <b>calibrated</b> if its predicted probabilities match empirical frequencies.<br><br><b>Example</b>: Among examples where the model predicts 0.8, about 80% should truly be positive.<br><br><b>Why useful</b>: Calibration matters when probabilities drive decisions (thresholding, ranking with costs, risk estimates), not just class labels.<br><br><b>How to check</b>: reliability diagram (calibration curve).<br><b>How to fix</b>: post-hoc calibration such as <b>temperature scaling</b> (common for neural nets).",
      "tags": [
        "ch04",
        "calibration",
        "evaluation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-056",
      "front": "What is focal loss and when is it used?",
      "back": "<b>Focal loss</b> down-weights easy examples to focus training on hard ones:<br><br>\\( FL(p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t) \\)<br><br>where \\( p_t \\) is the predicted probability for the true class.<br><br><b>Key idea</b>: The \\( (1 - p_t)^\\gamma \\) factor reduces the loss for well-classified examples (high \\( p_t \\)).<br><br><b>Parameters</b>:<ul><li>\\( \\gamma \\): Focusing parameter (typically 2). Higher = more focus on hard examples.</li><li>\\( \\alpha_t \\): Class weight for imbalance</li></ul><b>When to use</b>: Object detection (many easy negatives, few hard positives), extreme class imbalance.<br><br><b>Origin</b>: RetinaNet (2017).",
      "tags": [
        "ch04",
        "focal-loss",
        "imbalanced-classes"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-057",
      "front": "What is triplet loss?",
      "back": "<b>Triplet loss</b> learns embeddings where similar items are close and dissimilar items are far:<br><br>\\( L = \\max(0, d(a, p) - d(a, n) + m) \\)<br><br>where:<ul><li>\\( a \\) = anchor example</li><li>\\( p \\) = positive (same class as anchor)</li><li>\\( n \\) = negative (different class)</li><li>\\( d \\) = distance (e.g., Euclidean)</li><li>\\( m \\) = margin</li></ul><b>Goal</b>: Make \\( d(a, p) + m < d(a, n) \\) - positive closer than negative by at least margin \\( m \\).<br><br><b>Use cases</b>: Face recognition (FaceNet), image retrieval, one-shot learning.<br><br><b>Challenge</b>: Triplet mining - choosing informative triplets is crucial for training.",
      "tags": [
        "ch04",
        "triplet-loss",
        "metric-learning"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-058",
      "front": "What is the difference between hard and semi-hard triplet mining?",
      "back": "<b>Triplet mining</b> selects which (anchor, positive, negative) triplets to train on.<br><br><b>Hard negatives</b>: \\( d(a, n) < d(a, p) \\)<br>Negative is closer than positive - violates the desired ordering.<br><br><b>Semi-hard negatives</b>: \\( d(a, p) < d(a, n) < d(a, p) + m \\)<br>Negative is farther than positive but within the margin.<br><br><b>In practice</b>:<ul><li>Hard negatives can cause training collapse (always choosing impossible triplets)</li><li>Semi-hard negatives provide useful gradients without being too difficult</li><li>Online mining: Select from current batch</li><li>Offline mining: Pre-compute across dataset</li></ul>",
      "tags": [
        "ch04",
        "triplet-loss",
        "metric-learning"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-04-059",
      "front": "What is Huber loss (smooth L1 loss)?",
      "back": "<b>Huber loss</b> combines MSE and MAE to be robust to outliers:<br><br>\\( L_\\delta(y, f(x)) = \\begin{cases} \\frac{1}{2}(y - f(x))^2 & \\text{if } |y - f(x)| \\leq \\delta \\\\ \\delta |y - f(x)| - \\frac{1}{2}\\delta^2 & \\text{otherwise} \\end{cases} \\)<br><br><b>Intuition</b>: Acts like MSE for small errors (smooth gradients), but like MAE for large errors (less sensitive to outliers).<br><br><b>Properties</b>:<ul><li>Differentiable everywhere (unlike MAE)</li><li>Linear growth for large errors (unlike MSE's quadratic)</li><li>\\( \\delta \\) controls transition point</li></ul><b>Use cases</b>: Regression with outliers, object detection (bounding box regression), reinforcement learning.",
      "tags": [
        "ch04",
        "huber-loss",
        "robust-regression"
      ]
    }
  ]
}

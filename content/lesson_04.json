{
  "id": "04",
  "title": "Lesson 04: Single-layer Networks: Regression",
  "lesson_title": "Single-layer Networks: Regression",
  "objectives": [
    "Understand linear regression as a single-layer neural network",
    "Learn basis functions and feature extraction",
    "Master maximum likelihood for regression",
    "Understand the bias-variance trade-off",
    "Learn decision theory for regression",
    "Understand regularization and weight decay"
  ],
  "cards": [
    {
      "uid": "04-001",
      "front": "What is the goal of regression?",
      "back": "To predict the value of one or more <b>continuous target variables</b> \\( t \\) given the value of a D-dimensional vector \\( \\vec{x} \\) of input variables.",
      "tags": [
        "ch04",
        "regression",
        "basics"
      ]
    },
    {
      "uid": "04-002",
      "front": "What is the bias parameter in a linear regression model?",
      "back": "The parameter \\( w_0 \\) that allows for any fixed offset in the data:<br>\\( y(\\vec{x}, \\vec{w}) = w_0 + w_1 x_1 + \\ldots + w_D x_D \\)<br>Also called the intercept. Not to be confused with statistical bias.",
      "tags": [
        "ch04",
        "regression",
        "parameters"
      ]
    },
    {
      "uid": "04-003",
      "front": "What was feature extraction in pre-deep learning machine learning?",
      "back": "A form of fixed pre-processing of input variables \\( \\vec{x} \\) expressed as a set of <b>basis functions</b> \\( \\{\\phi_j(\\vec{x})\\} \\).<br>The goal was to choose sufficiently powerful basis functions that the learning task could be solved with a simple network model.<br>Deep learning avoids this by learning nonlinear transformations from data itself.",
      "tags": [
        "ch04",
        "feature-extraction",
        "basis-functions"
      ]
    },
    {
      "uid": "04-004",
      "front": "How can a polynomial regression model be expressed using basis functions?",
      "back": "For a single input variable \\( x \\), use basis functions:<br>\\( \\phi_j(x) = x^j \\)<br>So:<br>\\( y(x, \\vec{w}) = w_0 + w_1 x + w_2 x^2 + \\ldots = \\sum_{j=0}^{M-1} w_j x^j \\)",
      "tags": [
        "ch04",
        "polynomial",
        "basis-functions"
      ]
    },
    {
      "uid": "04-005",
      "front": "Why are models of the form \\( y(\\vec{x}, \\vec{w}) = \\sum_j w_j \\phi_j(\\vec{x}) \\) called linear models?",
      "back": "Because they are <b>linear in the parameters</b> \\( \\vec{w} \\), even though they can be nonlinear in the inputs \\( \\vec{x} \\) (via the basis functions \\( \\phi_j \\)).<br>This linearity in parameters greatly simplifies the analysis.",
      "tags": [
        "ch04",
        "linear-models",
        "basis-functions"
      ]
    },
    {
      "uid": "04-006",
      "front": "What is least-squares regression?",
      "back": "A method to find parameters by minimizing the <b>sum-of-squares error function</b>:<br>\\( E_D(\\vec{w}) = \\frac{1}{2} \\sum_{n=1}^{N} \\{t_n - \\vec{w}^T \\phi(\\vec{x}_n)\\}^2 \\)<br>Equivalent to maximum likelihood under Gaussian noise assumption.",
      "tags": [
        "ch04",
        "least-squares",
        "optimization"
      ]
    },
    {
      "uid": "04-007",
      "front": "Why is maximizing likelihood under Gaussian noise equivalent to minimizing sum-of-squares error?",
      "back": "The log likelihood under Gaussian noise is:<br>\\( \\ln p(\\mathbf{t}|X, \\vec{w}, \\sigma^2) = -\\frac{N}{2}\\ln\\sigma^2 - \\frac{N}{2}\\ln(2\\pi) - \\frac{1}{\\sigma^2}E_D(\\vec{w}) \\)<br>The first two terms are constants w.r.t. \\( \\vec{w} \\), so maximizing likelihood is equivalent to minimizing \\( E_D(\\vec{w}) \\).",
      "tags": [
        "ch04",
        "maximum-likelihood",
        "least-squares"
      ]
    },
    {
      "uid": "04-008",
      "front": "What are the normal equations for least-squares regression?",
      "back": "The closed-form solution for \\( \\vec{w} \\):<br>\\( \\vec{w}_{ML} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf{t} \\)<br>Where \\( \\Phi \\) is the design matrix with elements \\( \\Phi_{nj} = \\phi_j(\\vec{x}_n) \\).",
      "tags": [
        "ch04",
        "normal-equations",
        "least-squares"
      ]
    },
    {
      "uid": "04-009",
      "front": "What is the Moore-Penrose pseudo-inverse?",
      "back": "A generalization of matrix inverse to non-square matrices:<br>\\( \\Phi^\\dagger = (\\Phi^T \\Phi)^{-1} \\Phi^T \\)<br>Used in the normal equations: \\( \\vec{w}_{ML} = \\Phi^\\dagger \\mathbf{t} \\)<br>If \\( \\Phi \\) is square and invertible, \\( \\Phi^\\dagger = \\Phi^{-1} \\).",
      "tags": [
        "ch04",
        "pseudo-inverse",
        "linear-algebra"
      ]
    },
    {
      "uid": "04-010",
      "front": "What is a batch method in machine learning?",
      "back": "A method where the <b>entire training data set is processed at once</b> to update parameters.<br>Contrast with sequential/online methods that process data points one at a time.",
      "tags": [
        "ch04",
        "batch-learning",
        "training"
      ]
    },
    {
      "uid": "04-011",
      "front": "What are sequential algorithms (online algorithms)?",
      "back": "Algorithms that process data points <b>one at a time</b> and then discard them.<br>Important for:<br><ul><li>Online applications</li><li>Large datasets where batch processing is infeasible</li></ul>Also called online algorithms.",
      "tags": [
        "ch04",
        "online-learning",
        "sequential"
      ]
    },
    {
      "uid": "04-012",
      "front": "What is stochastic gradient descent (SGD)?",
      "back": "A sequential optimization algorithm where parameters are updated after each data point:<br>\\( \\vec{w}^{(\\tau+1)} = \\vec{w}^{(\\tau)} - \\eta \\nabla E_n \\)<br>Where:<br><ul><li>\\( \\eta \\) is the learning rate</li><li>\\( \\tau \\) is the iteration number</li><li>\\( E_n \\) is the error for point \\( n \\)</li></ul>Also called sequential gradient descent.",
      "tags": [
        "ch04",
        "sgd",
        "optimization"
      ]
    },
    {
      "uid": "04-013",
      "front": "What is the LMS (least-mean-squares) algorithm?",
      "back": "The application of stochastic gradient descent to the sum-of-squares error function:<br>\\( \\vec{w}^{(\\tau+1)} = \\vec{w}^{(\\tau)} + \\eta(t_n - \\vec{w}^{(\\tau)T}\\phi_n)\\phi_n \\)<br>A classic sequential learning algorithm for linear regression.",
      "tags": [
        "ch04",
        "lms",
        "sgd"
      ]
    },
    {
      "uid": "04-014",
      "front": "What is the simplest form of regularizer in regression?",
      "back": "The sum of squares of the weight vector elements (L2 regularization):<br>\\( E_W(\\vec{w}) = \\frac{1}{2}\\vec{w}^T\\vec{w} = \\frac{1}{2}\\|\\vec{w}\\|^2 \\)<br>Total error: \\( E(\\vec{w}) = E_D(\\vec{w}) + \\lambda E_W(\\vec{w}) \\)<br>Also called <b>parameter shrinkage</b> or <b>weight decay</b>.",
      "tags": [
        "ch04",
        "regularization",
        "weight-decay"
      ]
    },
    {
      "uid": "04-015",
      "front": "What are the two stages in solving a regression problem using probabilistic methods?",
      "back": "<ol><li><b>Inference stage</b>: Learn a model for the predictive distribution \\( p(t|\\vec{x}) \\) from training data</li></ol><ol><li><b>Decision stage</b>: Use the predictive distribution to make predictions, minimizing a loss function</li></ol>This separation is a key principle of decision theory.",
      "tags": [
        "ch04",
        "decision-theory",
        "inference"
      ]
    },
    {
      "uid": "04-016",
      "front": "What is a loss function in regression?",
      "back": "A function that quantifies the penalty for predicting \\( f(\\vec{x}) \\) when the true value is \\( t \\):<br>\\( L(t, f(\\vec{x})) \\)<br>The goal is to choose \\( f \\) to minimize the <b>expected loss</b> under the predictive distribution.",
      "tags": [
        "ch04",
        "loss-function",
        "decision-theory"
      ]
    },
    {
      "uid": "04-017",
      "front": "What is the difference between an error function and a loss function?",
      "back": "<b>Error function</b>: Used to set parameters during training to determine the conditional probability distribution \\( p(t|\\vec{x}) \\)<br><b>Loss function</b>: Governs how the conditional distribution is used to arrive at a predictive function \\( f(\\vec{x}) \\)<br>They serve different purposes in the learning pipeline.",
      "tags": [
        "ch04",
        "loss-function",
        "error-function"
      ]
    },
    {
      "uid": "04-018",
      "front": "What is the optimal prediction under squared loss?",
      "back": "The <b>conditional mean</b> (regression function):<br>\\( f^*(\\vec{x}) = E[t|\\vec{x}] = \\int t \\, p(t|\\vec{x}) \\, dt \\)<br>This minimizes the expected squared loss:<br>\\( E[L] = \\int\\int \\{f(\\vec{x}) - t\\}^2 p(\\vec{x}, t) \\, d\\vec{x} \\, dt \\)",
      "tags": [
        "ch04",
        "regression-function",
        "squared-loss"
      ]
    },
    {
      "uid": "04-019",
      "front": "How can you determine a suitable value for the regularization coefficient \\( \\lambda \\)?",
      "back": "Methods include:<br><ul><li><b>Validation set</b>: Hold out data to evaluate different \\( \\lambda \\) values</li><li><b>Cross-validation</b>: K-fold validation to estimate generalization error</li><li><b>Bayesian methods</b>: Place a prior on \\( \\lambda \\) and marginalize</li></ul>The optimal \\( \\lambda \\) balances bias and variance.",
      "tags": [
        "ch04",
        "regularization",
        "model-selection"
      ]
    },
    {
      "uid": "04-020",
      "front": "What is the bias-variance trade-off?",
      "back": "A decomposition showing that expected loss has three components:<br>\\( \\text{Expected loss} = (\\text{bias})^2 + \\text{variance} + \\text{noise} \\)<br>Very flexible models have <b>low bias but high variance</b>.<br>Simple models have <b>high bias but low variance</b>.<br>Optimal model complexity balances these.",
      "tags": [
        "ch04",
        "bias-variance",
        "model-selection"
      ]
    },
    {
      "uid": "04-021",
      "front": "What is the squared bias in the bias-variance decomposition?",
      "back": "The extent to which the <b>average prediction</b> over all possible datasets differs from the true value:<br>\\( (\\text{bias})^2 = \\{E_D[f(\\vec{x}; D)] - h(\\vec{x})\\}^2 \\)<br>Where \\( h(\\vec{x}) \\) is the true underlying function.",
      "tags": [
        "ch04",
        "bias-variance",
        "bias"
      ]
    },
    {
      "uid": "04-022",
      "front": "What is the variance in the bias-variance decomposition?",
      "back": "The extent to which solutions for individual datasets vary around their average:<br>\\( \\text{variance} = E_D[\\{f(\\vec{x}; D) - E_D[f(\\vec{x}; D)]\\}^2] \\)<br>Measures sensitivity to the particular training set used.",
      "tags": [
        "ch04",
        "bias-variance",
        "variance"
      ]
    },
    {
      "uid": "04-023",
      "front": "Why does the bias-variance decomposition have limited practical value?",
      "back": "Because it is based on <b>averages with respect to ensembles of datasets</b>.<br>In practice, we have only a single dataset, so we cannot directly measure these quantities.<br>Useful conceptually but hard to apply directly.",
      "tags": [
        "ch04",
        "bias-variance",
        "limitations"
      ]
    },
    {
      "uid": "04-024",
      "front": "Does overfitting arise in Bayesian settings?",
      "back": "<b>No</b> - overfitting does not arise when we marginalize over parameters in a Bayesian setting.<br>The Bayesian approach integrates over the posterior distribution of parameters rather than using a single point estimate, naturally incorporating uncertainty.",
      "tags": [
        "ch04",
        "overfitting",
        "bayesian"
      ]
    },
    {
      "uid": "04-025",
      "front": "How can averaging help with the bias-variance trade-off?",
      "back": "Averaging predictions from multiple models can reduce variance without increasing bias.<br>This is the basis for <b>ensemble methods</b> like:<br><ul><li>Bagging</li><li>Random forests</li><li>Model averaging</li></ul>Combines multiple high-variance models to get lower variance.",
      "tags": [
        "ch04",
        "ensemble",
        "averaging"
      ]
    },
    {
      "uid": "04-026",
      "front": "What is a decision region in classification?",
      "back": "A region of input space where all points are assigned to the same class.<br>The input space is divided into decision regions \\( R_k \\) for each class \\( C_k \\).",
      "tags": [
        "ch04",
        "classification",
        "decision-regions"
      ]
    },
    {
      "uid": "04-027",
      "front": "What are decision boundaries (decision surfaces)?",
      "back": "The boundaries between decision regions.<br>For a linear discriminant: the hyperplane where \\( y(\\vec{x}) = 0 \\), i.e., \\( \\vec{w}^T\\vec{x} + w_0 = 0 \\).",
      "tags": [
        "ch04",
        "classification",
        "decision-boundaries"
      ]
    },
    {
      "uid": "04-028",
      "front": "What does it mean for data to be linearly separable?",
      "back": "Data from different classes can be separated by a linear decision boundary (hyperplane).<br>If classes overlap, they are not linearly separable.",
      "tags": [
        "ch04",
        "classification",
        "linear-separability"
      ]
    },
    {
      "uid": "04-029",
      "front": "What is a discriminant function?",
      "back": "A function that takes an input vector \\( \\vec{x} \\) and assigns it directly to one of K classes.<br>Simplest form for two classes:<br>\\( y(\\vec{x}) = \\vec{w}^T\\vec{x} + w_0 \\)<br>Classify as \\( C_1 \\) if \\( y(\\vec{x}) > 0 \\), else \\( C_2 \\).",
      "tags": [
        "ch04",
        "classification",
        "discriminant"
      ]
    },
    {
      "uid": "04-030",
      "front": "What is the geometric interpretation of the weight vector in a linear discriminant?",
      "back": "The weight vector \\( \\vec{w} \\) is <b>orthogonal to the decision surface</b>.<br>The bias \\( w_0 \\) determines the <b>location</b> of the decision surface (its distance from the origin).",
      "tags": [
        "ch04",
        "classification",
        "geometry"
      ]
    },
    {
      "uid": "04-031",
      "front": "What is a one-versus-the-rest classifier?",
      "back": "For K classes, train K binary classifiers, each separating one class from all others combined.<br>Problem: Can lead to ambiguous regions where multiple classifiers claim the point, or no classifier claims it.",
      "tags": [
        "ch04",
        "multi-class",
        "classification"
      ]
    },
    {
      "uid": "04-032",
      "front": "What is a one-versus-one classifier?",
      "back": "For K classes, train \\( K(K-1)/2 \\) binary classifiers for every pair of classes.<br>Requires more classifiers than one-versus-the-rest but can still lead to ambiguous regions.",
      "tags": [
        "ch04",
        "multi-class",
        "classification"
      ]
    },
    {
      "uid": "04-033",
      "front": "For K-class linear discriminants, what shape are the decision regions?",
      "back": "The decision regions are always <b>singly connected and convex</b>.<br>This follows from the linearity of the discriminant functions.",
      "tags": [
        "ch04",
        "classification",
        "decision-regions"
      ]
    },
    {
      "uid": "04-034",
      "front": "What is a discriminative probabilistic model?",
      "back": "A model that directly models the posterior probability \\( p(C_k|\\vec{x}) \\) without modeling the class-conditional densities.<br>Examples: Logistic regression, neural network classifiers.<br>Contrast with generative models.",
      "tags": [
        "ch04",
        "discriminative",
        "probabilistic"
      ]
    },
    {
      "uid": "04-035",
      "front": "What is a generative probabilistic model?",
      "back": "A model that computes posterior probabilities using Bayes' theorem by modeling:<br><ul><li>Class-conditional densities \\( p(\\vec{x}|C_k) \\)</li><li>Prior probabilities \\( p(C_k) \\)</li></ul>Then uses: \\( p(C_k|\\vec{x}) = \\frac{p(\\vec{x}|C_k)p(C_k)}{p(\\vec{x})} \\)<br>Also models the input distribution \\( p(\\vec{x}) \\).",
      "tags": [
        "ch04",
        "generative",
        "probabilistic"
      ]
    },
    {
      "uid": "04-036",
      "front": "Why is least-squares sensitive to outliers?",
      "back": "Because the squared error heavily penalizes large deviations.<br>Outliers produce large residuals that disproportionately influence the solution.<br>Techniques sensitive to a few data points are said to <b>lack robustness</b>.",
      "tags": [
        "ch04",
        "least-squares",
        "robustness"
      ]
    },
    {
      "uid": "04-037",
      "front": "What is logistic regression?",
      "back": "A discriminative model for classification that models the posterior probability directly:<br>\\( p(C_1|\\vec{x}) = \\sigma(\\vec{w}^T\\vec{x}) = \\frac{1}{1 + e^{-\\vec{w}^T\\vec{x}}} \\)<br>Despite the name, it's used for classification, not regression.",
      "tags": [
        "ch04",
        "logistic-regression",
        "classification"
      ]
    },
    {
      "uid": "04-038",
      "front": "What is the naive Bayes model?",
      "back": "A generative model that assumes <b>conditional independence</b> of features given the class:<br>\\( p(\\vec{x}|C_k) = \\prod_i p(x_i|C_k) \\)<br>Often works well despite the strong independence assumption.",
      "tags": [
        "ch04",
        "naive-bayes",
        "generative"
      ]
    },
    {
      "uid": "04-039",
      "front": "What is the confusion matrix in classification?",
      "back": "A table showing prediction outcomes:<br>|  | Predicted + | Predicted - |<br>|--|-------------|-------------|<br>| Actual + | True Positive (TP) | False Negative (FN) |<br>| Actual - | False Positive (FP) | True Negative (TN) |<br>False positives = Type 1 errors<br>False negatives = Type 2 errors",
      "tags": [
        "ch04",
        "confusion-matrix",
        "evaluation"
      ]
    },
    {
      "uid": "04-040",
      "front": "Why can accuracy be misleading for imbalanced classes?",
      "back": "With strongly imbalanced classes, a naive classifier that always predicts the majority class can achieve high accuracy.<br>Example: 99% negative class - predicting all negative gives 99% accuracy but is useless.<br>Need metrics like precision, recall, F-score instead.",
      "tags": [
        "ch04",
        "accuracy",
        "imbalanced-classes"
      ]
    },
    {
      "uid": "04-041",
      "front": "What is precision in classification?",
      "back": "The fraction of positive predictions that are correct:<br>\\( \\text{Precision} = \\frac{TP}{TP + FP} \\)<br>Represents the probability that a positive prediction is actually positive.<br>Also called Positive Predictive Value (PPV).",
      "tags": [
        "ch04",
        "precision",
        "evaluation"
      ]
    },
    {
      "uid": "04-042",
      "front": "What is recall in classification?",
      "back": "The fraction of actual positives that are correctly identified:<br>\\( \\text{Recall} = \\frac{TP}{TP + FN} \\)<br>Also called sensitivity or True Positive Rate (TPR).",
      "tags": [
        "ch04",
        "recall",
        "evaluation"
      ]
    },
    {
      "uid": "04-043",
      "front": "What is the false positive rate (FPR)?",
      "back": "The fraction of actual negatives that are incorrectly classified as positive:<br>\\( \\text{FPR} = \\frac{FP}{FP + TN} \\)<br>Also called the fall-out rate. Used in ROC curves.",
      "tags": [
        "ch04",
        "fpr",
        "evaluation"
      ]
    },
    {
      "uid": "04-044",
      "front": "What is the false discovery rate (FDR)?",
      "back": "The fraction of positive predictions that are incorrect:<br>\\( \\text{FDR} = \\frac{FP}{FP + TP} = 1 - \\text{Precision} \\)<br>The complement of precision.",
      "tags": [
        "ch04",
        "fdr",
        "evaluation"
      ]
    },
    {
      "uid": "04-045",
      "front": "What is an ROC curve?",
      "back": "<b>Receiver Operating Characteristic</b> curve: a plot of True Positive Rate vs False Positive Rate as the classification threshold varies.<br>Each point represents a different threshold, giving a different confusion matrix.<br>Useful for comparing classifiers and choosing operating points.",
      "tags": [
        "ch04",
        "roc",
        "evaluation"
      ]
    },
    {
      "uid": "04-046",
      "front": "What does a classifier below the diagonal mean on an ROC curve?",
      "back": "It performs <b>worse than random guessing</b>.<br>The diagonal represents random classification.<br>Above diagonal = better than random.<br>Perfect classifier = top-left corner (TPR=1, FPR=0).",
      "tags": [
        "ch04",
        "roc",
        "evaluation"
      ]
    },
    {
      "uid": "04-047",
      "front": "What is AUC (Area Under the ROC Curve)?",
      "back": "A summary measure of classifier performance:<br><ul><li>AUC = 0.5: Random guessing</li><li>AUC = 1.0: Perfect classifier</li></ul>Represents the probability that a randomly chosen positive example ranks higher than a randomly chosen negative example.",
      "tags": [
        "ch04",
        "auc",
        "evaluation"
      ]
    },
    {
      "uid": "04-048",
      "front": "What is the F-score?",
      "back": "The harmonic mean of precision and recall:<br>\\( F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\)<br>Balances precision and recall. The general \\( F_\\beta \\) score weights recall \\( \\beta \\) times as much as precision.",
      "tags": [
        "ch04",
        "f-score",
        "evaluation"
      ]
    },
    {
      "uid": "04-049",
      "front": "What is the reject option in classification?",
      "back": "Refusing to classify inputs where the classifier is uncertain.<br>Implemented by introducing a threshold \\( \\theta \\) and rejecting inputs where the largest posterior probability \\( \\max_k p(C_k|\\vec{x}) < \\theta \\).<br>Reduces errors at the cost of leaving some inputs unclassified.",
      "tags": [
        "ch04",
        "reject-option",
        "classification"
      ]
    },
    {
      "uid": "04-050",
      "front": "What are four reasons to compute posterior probabilities even if you just need class predictions?",
      "back": "<ol><li><b>Minimizing risk</b>: Incorporate different misclassification costs</li></ol><ol><li><b>Reject option</b>: Refuse uncertain predictions</li></ol><ol><li><b>Compensating for class priors</b>: Adjust for different train/test class distributions</li></ol><ol><li><b>Combining models</b>: Properly combine predictions from multiple models</li></ol>",
      "tags": [
        "ch04",
        "posterior",
        "decision-theory"
      ]
    },
    {
      "uid": "04-051",
      "front": "What is outlier detection (novelty detection)?",
      "back": "Identifying inputs that differ significantly from the training data.<br>Important when test data may contain examples from classes not seen during training.<br>Generative models are naturally suited for this since they model \\( p(\\vec{x}) \\).",
      "tags": [
        "ch04",
        "outlier-detection",
        "novelty-detection"
      ]
    }
  ]
}

{
  "id": "20",
  "title": "Lesson 20: Diffusion Models",
  "lesson_title": "Diffusion Models",
  "objectives": [
    "Understand the forward noising process in diffusion models",
    "Learn the reverse denoising process",
    "Master the diffusion model ELBO and training objective",
    "Understand noise prediction and sampling",
    "Learn about score-based models and connections"
  ],
  "cards": [
    {
      "uid": "20-001",
      "front": "What is a diffusion model?",
      "back": "A generative model that learns to **reverse a gradual noising process**.\n\nTwo processes:\n\n1. **Forward**: Gradually add noise until data becomes pure Gaussian noise\n2. **Reverse**: Learn neural network to denoise step by step\n\nSampling: Start from noise, iteratively denoise to generate data.",
      "tags": ["ch20", "diffusion", "definition"]
    },
    {
      "uid": "20-002",
      "front": "What is the forward noising process in diffusion models?",
      "back": "A Markov chain that gradually adds Gaussian noise:\n\n\\( q(z_t | z_{t-1}) = \\mathcal{N}(z_t | \\sqrt{1-\\beta_t} z_{t-1}, \\beta_t I) \\)\n\nStarting from x = \\( z_0 \\), after T steps, \\( z_T \\) is approximately standard Gaussian.\n\nNo learnable parameters - just fixed noise schedule \\( \\{\\beta_t\\} \\).",
      "tags": ["ch20", "forward-process", "noising"]
    },
    {
      "uid": "20-003",
      "front": "What is the diffusion kernel?",
      "back": "A formula to sample **any step directly** without iterating:\n\n\\( q(z_t | x) = \\mathcal{N}(z_t | \\sqrt{\\alpha_t} x, (1-\\alpha_t) I) \\)\n\nwhere \\( \\alpha_t = \\prod_{\\tau=1}^{t} (1-\\beta_\\tau) \\)\n\nEnables efficient training by jumping to any timestep.",
      "tags": ["ch20", "diffusion-kernel", "efficiency"]
    },
    {
      "uid": "20-004",
      "front": "What is the reverse denoising process in diffusion models?",
      "back": "A learned Markov chain that removes noise:\n\n\\( p(z_{t-1} | z_t, w) = \\mathcal{N}(z_{t-1} | \\mu(z_t, w, t), \\beta_t I) \\)\n\nNeural network \\( \\mu(z_t, w, t) \\) predicts the mean of denoised distribution.\n\nOne network handles all timesteps (t is an input).",
      "tags": ["ch20", "reverse-process", "denoising"]
    },
    {
      "uid": "20-005",
      "front": "Why does the reverse process work for small noise steps?",
      "back": "When \\( \\beta_t \\ll 1 \\):\n\n- Forward step changes z only slightly\n- True reverse \\( q(z_{t-1}|z_t) \\) is approximately Gaussian\n\nNeural network only needs to model Gaussian mean.\n\nTrade-off: Small steps → many steps needed (T often 1000+).",
      "tags": ["ch20", "small-steps", "approximation"]
    },
    {
      "uid": "20-006",
      "front": "How is the diffusion model trained?",
      "back": "Maximize the **ELBO** (evidence lower bound):\n\n\\( L(w) = E_q[\\ln p(x|z_1)] - \\sum_{t=2}^{T} D_{KL}(q(z_{t-1}|z_t,x) || p(z_{t-1}|z_t,w)) \\)\n\nTwo parts:\n\n1. **Reconstruction**: Generate x from \\( z_1 \\)\n2. **Consistency**: Match reverse to true posterior at each step",
      "tags": ["ch20", "elbo", "training"]
    },
    {
      "uid": "20-007",
      "front": "Why predict noise instead of the denoised image?",
      "back": "Instead of network \\( \\mu \\) predicting denoised mean, network g predicts **total noise added**:\n\n\\( g(z_t, w, t) \\approx \\epsilon_t \\)\n\nAdvantages:\n\n- Simpler objective function\n- Better empirical results\n- Unified handling of all timesteps",
      "tags": ["ch20", "noise-prediction", "training"]
    },
    {
      "uid": "20-008",
      "front": "What is the simplified diffusion training loss?",
      "back": "\\( L(w) = -\\sum_t ||g(\\sqrt{\\alpha_t} x + \\sqrt{1-\\alpha_t} \\epsilon, w, t) - \\epsilon||^2 \\)\n\nSimple interpretation:\n\n1. Create noisy version of x using sampled noise \\( \\epsilon \\)\n2. Train network to predict what noise was added\n3. Squared error between predicted and actual noise",
      "tags": ["ch20", "loss-function", "training"]
    },
    {
      "uid": "20-009",
      "front": "How does stochastic gradient descent work for diffusion training?",
      "back": "For each training step:\n\n1. Sample data point x from training set\n2. Sample random timestep t from \\( \\{1, ..., T\\} \\)\n3. Sample noise \\( \\epsilon \\sim \\mathcal{N}(0, I) \\)\n4. Compute noisy \\( z_t \\) using diffusion kernel\n5. Train network to predict \\( \\epsilon \\)\n\nBuilt-in data augmentation: Same x gets different noise each time.",
      "tags": ["ch20", "sgd", "training"]
    },
    {
      "uid": "20-010",
      "front": "How do you generate samples from a trained diffusion model?",
      "back": "Starting from \\( z_T \\sim \\mathcal{N}(0, I) \\):\n\nFor t = T to 1:\n\n1. Predict noise: \\( \\hat{\\epsilon} = g(z_t, w, t) \\)\n2. Compute mean: \\( \\mu = \\frac{1}{\\sqrt{1-\\beta_t}}(z_t - \\frac{\\beta_t}{\\sqrt{1-\\alpha_t}} \\hat{\\epsilon}) \\)\n3. Sample: \\( z_{t-1} = \\mu + \\sqrt{\\beta_t} \\epsilon \\) (except t=1)\n\nFinal \\( z_0 \\) is the generated sample.",
      "tags": ["ch20", "sampling", "generation"]
    },
    {
      "uid": "20-011",
      "front": "What is the main computational drawback of diffusion models?",
      "back": "Sampling requires **multiple sequential passes** through the network.\n\nTypically T = 1000+ steps.\n\nMuch slower than:\n\n- GANs (single forward pass)\n- VAEs (single forward pass)\n- Normalizing flows (single forward pass)\n\nMitigation: Faster sampling methods, continuous-time formulations.",
      "tags": ["ch20", "sampling", "cost"]
    },
    {
      "uid": "20-012",
      "front": "What is a U-Net in the context of diffusion models?",
      "back": "A common neural network architecture for the denoising network.\n\nStructure:\n\n- Encoder: Progressively downsample\n- Decoder: Progressively upsample\n- Skip connections: Connect encoder to decoder at each scale\n\nOutput has same dimensionality as input (predicts noise).",
      "tags": ["ch20", "unet", "architecture"]
    },
    {
      "uid": "20-013",
      "front": "How does the noise schedule \\( \\{\\beta_t\\} \\) affect diffusion models?",
      "back": "The schedule controls how fast noise is added:\n\n- **Linear**: \\( \\beta_t \\) increases linearly\n- **Cosine**: Smoother noise addition, often works better\n\nKey property: After T steps, data should be approximately standard Gaussian.\n\nTypical: \\( \\beta_1 \\approx 10^{-4} \\), \\( \\beta_T \\approx 0.02 \\).",
      "tags": ["ch20", "noise-schedule", "hyperparameter"]
    },
    {
      "uid": "20-014",
      "front": "What is the relationship between diffusion models and score matching?",
      "back": "The denoising network implicitly learns the **score function**:\n\n\\( \\nabla_z \\ln p(z) \\)\n\nNoise prediction ≈ negative score.\n\nConnects to:\n\n- Score-based generative models\n- Langevin dynamics sampling\n- Denoising score matching",
      "tags": ["ch20", "score-matching", "theory"]
    },
    {
      "uid": "20-015",
      "front": "What are the advantages of diffusion models over GANs?",
      "back": "1. **Stable training**: No adversarial dynamics\n\n2. **Mode coverage**: Don't suffer from mode collapse\n\n3. **Likelihood**: Can compute ELBO (approximate likelihood)\n\n4. **Quality**: State-of-the-art image generation\n\nTrade-off: Slower sampling than GANs.",
      "tags": ["ch20", "diffusion-vs-gan", "comparison"]
    },
    {
      "uid": "20-016",
      "front": "Why do diffusion models have the same latent and data dimensionality?",
      "back": "The forward process adds noise to x, creating latent \\( z_t \\) of same size.\n\nNo compression like VAE bottleneck.\n\nSimilar to normalizing flows in this respect.\n\nThe 'latent' is just a noisy version of data, not a compact representation.",
      "tags": ["ch20", "dimensionality", "architecture"]
    },
    {
      "uid": "20-017",
      "front": "How does conditioning work in diffusion models?",
      "back": "Add conditioning information c to the denoising network:\n\n\\( g(z_t, w, t, c) \\)\n\nExamples:\n\n- **Text-to-image**: c = text embedding\n- **Class-conditional**: c = class label\n- **Image editing**: c = input image + mask\n\nEnables controllable generation.",
      "tags": ["ch20", "conditioning", "control"]
    },
    {
      "uid": "20-018",
      "front": "What is classifier-free guidance in diffusion models?",
      "back": "A technique to strengthen conditioning without a separate classifier.\n\nTrain both:\n\n- Conditional model: \\( g(z_t, w, t, c) \\)\n- Unconditional model: \\( g(z_t, w, t) \\)\n\nAt sampling: \\( \\hat{g} = g_{uncond} + s \\cdot (g_{cond} - g_{uncond}) \\)\n\nScale s > 1 strengthens conditioning effect.",
      "tags": ["ch20", "guidance", "conditioning"]
    }
  ]
}

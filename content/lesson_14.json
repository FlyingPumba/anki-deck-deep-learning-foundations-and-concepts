{
  "id": "14",
  "title": "Lesson 14: Sampling",
  "lesson_title": "Sampling",
  "objectives": [
    "Understand basic sampling algorithms and their limitations",
    "Learn rejection sampling and importance sampling",
    "Master Markov chain Monte Carlo methods",
    "Understand the Metropolis-Hastings algorithm",
    "Learn Gibbs sampling and Langevin dynamics"
  ],
  "cards": [
    {
      "uid": "14-001",
      "front": "What is Monte Carlo sampling?",
      "back": "The process of creating synthetic examples of a variable z from a probability distribution p(z).<br>Used to:<br><ul><li>Evaluate expectations</li><li>Generate samples from complex distributions</li><li>Train energy-based models</li></ul>",
      "tags": [
        "ch14",
        "sampling",
        "monte-carlo"
      ]
    },
    {
      "uid": "14-002",
      "front": "How can expectations be approximated using sampling?",
      "back": "Given L independent samples \\( z^{(l)} \\) from p(z):<br>\\( E[f] \\approx \\frac{1}{L} \\sum_{l=1}^{L} f(z^{(l)}) \\)<br>The variance decreases as 1/L, <b>independent of dimensionality</b>.<br>Key challenge: samples might not be truly independent.",
      "tags": [
        "ch14",
        "expectations",
        "estimation"
      ]
    },
    {
      "uid": "14-003",
      "front": "What is the transformation method for sampling?",
      "back": "If z is uniform over (0,1), transform using \\( y = h^{-1}(z) \\) where h(y) is the <b>indefinite integral</b> of desired distribution p(y).<br>Limitation: Only works when the inverse of the indefinite integral can be computed analytically.",
      "tags": [
        "ch14",
        "transformation",
        "basic-sampling"
      ]
    },
    {
      "uid": "14-004",
      "front": "What is the Box-Muller method?",
      "back": "A technique for generating <b>Gaussian-distributed</b> random numbers from uniform samples.<br>Steps:<br><ol><li>Generate pairs uniformly in unit circle</li><li>Transform using specific equations</li><li>Result: two independent standard Gaussians</li></ol>For general multivariate Gaussian: use Cholesky decomposition.",
      "tags": [
        "ch14",
        "box-muller",
        "gaussian"
      ]
    },
    {
      "uid": "14-005",
      "front": "What is rejection sampling?",
      "back": "A method to sample from complex distribution p(z) using a simpler proposal q(z).<br>Requirements:<br><ul><li>Find k such that \\( kq(z) \\geq \\tilde{p}(z) \\) everywhere</li><li>Sample from q(z)</li><li>Accept with probability \\( \\tilde{p}(z)/kq(z) \\)</li></ul>Rejected samples are discarded.",
      "tags": [
        "ch14",
        "rejection-sampling",
        "basic-sampling"
      ]
    },
    {
      "uid": "14-006",
      "front": "Why does rejection sampling fail in high dimensions?",
      "back": "The acceptance rate <b>decreases exponentially</b> with dimensionality.<br>Even if proposal q(z) is close to p(z), the ratio of volumes causes exponential rejection.<br>Example: If \\( \\sigma_q \\) exceeds \\( \\sigma_p \\) by 1%, acceptance rate in D=1000 dimensions is approximately 1/20,000.",
      "tags": [
        "ch14",
        "rejection-sampling",
        "limitations"
      ]
    },
    {
      "uid": "14-007",
      "front": "What is importance sampling?",
      "back": "A framework for approximating <b>expectations</b> directly (not for drawing samples).<br>\\( E[f] \\approx \\frac{1}{L} \\sum_{l=1}^{L} \\frac{p(z^{(l)})}{q(z^{(l)})} f(z^{(l)}) \\)<br>The ratios \\( r_l = p(z^{(l)})/q(z^{(l)}) \\) are <b>importance weights</b>.<br>All generated samples are retained.",
      "tags": [
        "ch14",
        "importance-sampling",
        "expectations"
      ]
    },
    {
      "uid": "14-008",
      "front": "What is a key drawback of importance sampling?",
      "back": "Can produce results that are <b>arbitrarily wrong with no diagnostic indication</b>.<br>If p(z)f(z) is concentrated in regions where q(z) is small:<br><ul><li>Few samples have large weights</li><li>Effective sample size much smaller than L</li><li>Estimate may be severely wrong</li></ul>",
      "tags": [
        "ch14",
        "importance-sampling",
        "limitations"
      ]
    },
    {
      "uid": "14-009",
      "front": "What is Markov chain Monte Carlo (MCMC)?",
      "back": "A framework for sampling from complex distributions that <b>scales well with dimensionality</b>.<br>Key idea: Generate a sequence of samples forming a <b>Markov chain</b> that converges to the target distribution.<br>The proposal distribution \\( q(z|z^{(\\tau)}) \\) is conditioned on the current state.",
      "tags": [
        "ch14",
        "mcmc",
        "markov-chain"
      ]
    },
    {
      "uid": "14-010",
      "front": "Why are random walks inefficient for sampling?",
      "back": "After \\( \\tau \\) steps, a random walk travels only distance proportional to \\( \\sqrt{\\tau} \\).<br>This square-root dependence means very slow exploration of state space.<br><b>Central goal</b> of MCMC design: avoid random walk behaviour.",
      "tags": [
        "ch14",
        "random-walk",
        "efficiency"
      ]
    },
    {
      "uid": "14-011",
      "front": "What is a first-order Markov chain?",
      "back": "A sequence of random variables where each depends <b>only on the previous state</b>:<br>\\( p(z^{(m+1)}|z^{(1)}, \\ldots, z^{(m)}) = p(z^{(m+1)}|z^{(m)}) \\)<br>Can be represented as a directed graphical model in chain form.",
      "tags": [
        "ch14",
        "markov-chain",
        "definition"
      ]
    },
    {
      "uid": "14-012",
      "front": "What are transition probabilities in a Markov chain?",
      "back": "Conditional distributions \\( T(z', z) \\equiv p(z'|z) \\) specifying how the chain moves between states.<br>A chain is <b>homogeneous</b> if transition probabilities are the same for all steps.",
      "tags": [
        "ch14",
        "markov-chain",
        "transition"
      ]
    },
    {
      "uid": "14-013",
      "front": "What is an invariant (stationary) distribution?",
      "back": "A distribution \\( p^<i>(z) \\) that is <b>unchanged</b> by one step of the Markov chain:<br>\\( p^</i>(z) = \\int T(z', z) p^*(z') dz' \\)<br>A Markov chain may have more than one invariant distribution.",
      "tags": [
        "ch14",
        "invariant",
        "stationary"
      ]
    },
    {
      "uid": "14-014",
      "front": "What is the detailed balance condition?",
      "back": "A <b>sufficient condition</b> for a distribution to be invariant:<br>\\( p^<i>(z) T(z, z') = p^</i>(z') T(z', z) \\)<br>A Markov chain satisfying detailed balance is called <b>reversible</b>.",
      "tags": [
        "ch14",
        "detailed-balance",
        "reversibility"
      ]
    },
    {
      "uid": "14-015",
      "front": "What is ergodicity in Markov chains?",
      "back": "The property that the chain converges to a unique <b>equilibrium distribution</b> \\( p^*(z) \\) regardless of the initial distribution.<br>An ergodic chain has exactly one invariant distribution.<br>Required for MCMC to sample correctly.",
      "tags": [
        "ch14",
        "ergodicity",
        "convergence"
      ]
    },
    {
      "uid": "14-016",
      "front": "What is the Metropolis algorithm?",
      "back": "A basic MCMC algorithm with <b>symmetric</b> proposal distribution.<br>Acceptance probability:<br>\\( A(z^<i>, z^{(\\tau)}) = \\min\\left(1, \\frac{\\tilde{p}(z^</i>)}{\\tilde{p}(z^{(\\tau)})}\\right) \\)<br>If rejected, the <b>previous sample is kept</b> (unlike rejection sampling where samples are discarded).",
      "tags": [
        "ch14",
        "metropolis",
        "mcmc"
      ]
    },
    {
      "uid": "14-017",
      "front": "What is the Metropolis-Hastings algorithm?",
      "back": "Generalization of Metropolis for <b>asymmetric</b> proposals.<br>Acceptance probability:<br>\\( A(z^<i>, z^{(\\tau)}) = \\min\\left(1, \\frac{\\tilde{p}(z^</i>) q(z^{(\\tau)}|z^<i>)}{\\tilde{p}(z^{(\\tau)}) q(z^</i>|z^{(\\tau)})}\\right) \\)<br>Reduces to Metropolis when q is symmetric.",
      "tags": [
        "ch14",
        "metropolis-hastings",
        "mcmc"
      ]
    },
    {
      "uid": "14-018",
      "front": "What is the trade-off in choosing proposal distribution variance for Metropolis-Hastings?",
      "back": "<b>Small variance</b>:<br><ul><li>High acceptance rate</li><li>Slow random walk, long correlation times</li></ul><b>Large variance</b>:<br><ul><li>High rejection rate</li><li>Many proposed steps to low-probability regions</li></ul>Optimal: variance similar to smallest length scale of target distribution.",
      "tags": [
        "ch14",
        "metropolis-hastings",
        "tuning"
      ]
    },
    {
      "uid": "14-019",
      "front": "What is Gibbs sampling?",
      "back": "A special case of Metropolis-Hastings where each variable is updated by sampling from its <b>conditional distribution</b> given all others:<br>\\( z_i \\sim p(z_i | z_{\\backslash i}) \\)<br>Acceptance probability is always 1.<br>Widely applicable when conditionals are tractable.",
      "tags": [
        "ch14",
        "gibbs-sampling",
        "mcmc"
      ]
    },
    {
      "uid": "14-020",
      "front": "Why does Gibbs sampling suffer from slow mixing with correlated variables?",
      "back": "Step size is governed by <b>conditional distributions</b> (width l), not marginals (width L).<br>For correlated Gaussian: number of steps for independent sample is \\( O((L/l)^2) \\).<br>Solutions: Over-relaxation, blocking (sampling groups of variables together).",
      "tags": [
        "ch14",
        "gibbs-sampling",
        "correlation"
      ]
    },
    {
      "uid": "14-021",
      "front": "What is over-relaxation in Gibbs sampling?",
      "back": "A technique to reduce random walk behaviour when conditionals are Gaussian.<br>Update: \\( z_i' = \\mu_i + \\alpha(z_i - \\mu_i) + \\sigma_i\\sqrt{1-\\alpha^2}\\nu \\)<br>With \\( \\alpha < 0 \\): step is biased to <b>opposite side of mean</b>, encouraging directed motion.",
      "tags": [
        "ch14",
        "over-relaxation",
        "gibbs-sampling"
      ]
    },
    {
      "uid": "14-022",
      "front": "What is ancestral sampling?",
      "back": "Sampling from a directed graphical model by making <b>one pass</b> through variables in topological order:<br>For each node: sample from \\( p(z_i | \\text{pa}(i)) \\)<br>Works because parent values are already instantiated.<br>Produces exact samples from joint distribution.",
      "tags": [
        "ch14",
        "ancestral-sampling",
        "graphical-models"
      ]
    },
    {
      "uid": "14-023",
      "front": "What is an energy-based model?",
      "back": "A model defined by an <b>energy function</b> E(x, w):<br>\\( p(x|w) = \\frac{1}{Z(w)} \\exp\\{-E(x, w)\\} \\)<br>Higher energy = lower probability.<br>Advantage: No normalization constraint on E.<br>Challenge: Partition function Z(w) is often intractable.",
      "tags": [
        "ch14",
        "energy-based",
        "model"
      ]
    },
    {
      "uid": "14-024",
      "front": "How is the gradient of log likelihood for energy-based models decomposed?",
      "back": "\\( \\nabla_w E_{x \\sim p_D}[\\ln p(x|w)] = -E_{x \\sim p_D}[\\nabla_w E(x,w)] + E_{x \\sim p_M}[\\nabla_w E(x,w)] \\)<br>First term: <b>push energy down</b> at data points<br>Second term: <b>push energy up</b> at model samples<br>Equilibrium when model matches data distribution.",
      "tags": [
        "ch14",
        "energy-based",
        "training"
      ]
    },
    {
      "uid": "14-025",
      "front": "What is the score function?",
      "back": "The gradient of log likelihood with respect to <b>data</b> x:<br>\\( s(x, w) = \\nabla_x \\ln p(x|w) \\)<br>For energy-based models:<br>\\( s(x, w) = -\\nabla_x E(x, w) \\)<br>Partition function disappears since it's independent of x.",
      "tags": [
        "ch14",
        "score-function",
        "gradient"
      ]
    },
    {
      "uid": "14-026",
      "front": "What is Langevin sampling (stochastic gradient Langevin dynamics)?",
      "back": "An MCMC method using gradient of log probability:<br>\\( x^{(\\tau+1)} = x^{(\\tau)} + \\eta \\nabla_x \\ln p(x^{(\\tau)}, w) + \\sqrt{2\\eta} \\epsilon^{(\\tau)} \\)<br>where \\( \\epsilon \\sim N(0, I) \\).<br>As \\( \\eta \\to 0 \\) and \\( T \\to \\infty \\): produces samples from p(x).",
      "tags": [
        "ch14",
        "langevin",
        "mcmc"
      ]
    },
    {
      "uid": "14-027",
      "front": "What is contrastive divergence?",
      "back": "An approximation for training energy-based models.<br>Instead of running long MCMC chains:<br><ul><li>Start chain from a training data point</li><li>Run only <b>a few steps</b> (even just one)</li><li>Use resulting sample for gradient estimation</li></ul>Trade-off: Biased but computationally efficient.",
      "tags": [
        "ch14",
        "contrastive-divergence",
        "training"
      ]
    },
    {
      "uid": "14-028",
      "front": "What is sampling-importance-resampling (SIR)?",
      "back": "A two-stage sampling approach:<br><ol><li>Draw L samples from proposal q(z)</li><li>Compute importance weights</li><li>Resample from discrete distribution with these weights</li></ol>Results are approximately from p(z), becoming exact as \\( L \\to \\infty \\).<br>Avoids determining constant k needed for rejection sampling.",
      "tags": [
        "ch14",
        "sir",
        "resampling"
      ]
    },
    {
      "uid": "14-029",
      "front": "What is adaptive rejection sampling?",
      "back": "Constructing the envelope function <b>on the fly</b> during sampling.<br>For <b>log-concave</b> distributions:<br><ul><li>Use tangent lines at grid points</li><li>Envelope is piecewise exponential</li><li>If sample rejected, add new grid point to refine envelope</li></ul>Envelope improves with more samples.",
      "tags": [
        "ch14",
        "adaptive-rejection",
        "log-concave"
      ]
    },
    {
      "uid": "14-030",
      "front": "How can base transitions be combined in MCMC?",
      "back": "Two ways to combine transitions \\( B_1, \\ldots, B_K \\):<br><ol><li><b>Mixture</b>: \\( T(z', z) = \\sum_k \\alpha_k B_k(z', z) \\)</li></ol><ol><li><b>Successive application</b>: Apply each in sequence</li></ol>If each preserves invariant distribution, so does the combination.<br>Useful for updating subsets of variables.",
      "tags": [
        "ch14",
        "mcmc",
        "transitions"
      ]
    }
  ]
}

{
  "id": "01",
  "title": "Lesson 01: The Deep Learning Revolution",
  "lesson_title": "The Deep Learning Revolution",
  "objectives": [
    "Understand the relationship between machine learning, AI, and deep learning",
    "Distinguish between supervised, unsupervised, and self-supervised learning",
    "Understand classification vs regression problems",
    "Learn the concepts of overfitting, regularization, and model selection",
    "Understand the historical development of neural networks"
  ],
  "cards": [
    {
      "uid": "deep-learning-foundations-and-concepts-01-001",
      "front": "What is the relationship between the terms 'machine learning' and 'AI'?",
      "back": "The terms machine learning and AI are often used interchangeably. Many AI systems in current use represent applications of machine learning designed to solve specific problems.",
      "tags": [
        "ch01",
        "terminology",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-002",
      "front": "What are the adjustable parameters in a deep neural network called?",
      "back": "They are called <b>weights</b>.",
      "tags": [
        "ch01",
        "neural-networks",
        "terminology"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-003",
      "front": "What is the process of setting parameter values from data called in machine learning?",
      "back": "It is called <b>learning</b> or <b>training</b>.",
      "tags": [
        "ch01",
        "training",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-004",
      "front": "What is a classification problem?",
      "back": "A <b>classification problem</b> is one where each input must be assigned to a discrete set of classes (e.g., benign or malignant).",
      "tags": [
        "ch01",
        "classification",
        "supervised-learning"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-005",
      "front": "What is a regression problem?",
      "back": "A <b>regression problem</b> is one where the output consists of one or more continuous variables (e.g., predicting the yield in a chemical process given temperature and pressure).",
      "tags": [
        "ch01",
        "regression",
        "supervised-learning"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-006",
      "front": "What is supervised learning?",
      "back": "<b>Supervised learning</b> is when the network is told the correct label for each training example. The training data consists of input-output pairs.",
      "tags": [
        "ch01",
        "supervised-learning",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-007",
      "front": "What is unsupervised learning?",
      "back": "<b>Unsupervised learning</b> is when the training data consists of unlabelled examples, and the goal is to discover structure or patterns in the data (e.g., generating new images that share statistical properties with training images).",
      "tags": [
        "ch01",
        "unsupervised-learning",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-008",
      "front": "What is self-supervised learning?",
      "back": "<b>Self-supervised learning</b> is when a function from inputs to outputs is learned, but the labelled outputs are obtained automatically from the input training data without needing separate human-derived labels.<br>Example: predicting the next word in a sequence, where the target is derived from the text itself.",
      "tags": [
        "ch01",
        "self-supervised-learning",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-010",
      "front": "What is a generative model?",
      "back": "A <b>generative model</b> can generate new output examples that differ from those used to train the model but share the same statistical properties.",
      "tags": [
        "ch01",
        "generative-models",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-023",
      "front": "What is the perceptron and what is its historical significance?",
      "back": "The <b>perceptron</b> (Rosenblatt, 1962) is a single-layer neural network with a step activation function:<br>\\( f(a) = \\begin{cases} 0, & \\text{if } a \\leq 0 \\\\ 1, & \\text{if } a > 0 \\end{cases} \\)<br>It was one of the first trainable neural network models, but Minsky and Papert (1969) gave formal proofs of its limited capabilities.",
      "tags": [
        "ch01",
        "perceptron",
        "history"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-024",
      "front": "What is a multilayer perceptron (MLP)?",
      "back": "A <b>multilayer perceptron (MLP)</b> is a modern neural network with multiple layers of learnable parameters. Despite the name, it uses continuous differentiable activation functions (not step functions like the original perceptron).",
      "tags": [
        "ch01",
        "mlp",
        "neural-networks"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-025",
      "front": "What two key changes enabled training of multilayer neural networks?",
      "back": "<ol><li>Replace the step function with <b>continuous differentiable activation functions</b> having non-zero gradients</li><li>Introduce <b>differentiable error functions</b> that define how well parameter values predict target variables</li></ol>",
      "tags": [
        "ch01",
        "backpropagation",
        "history"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-031",
      "front": "What is feature extraction in traditional machine learning?",
      "back": "<b>Feature extraction</b> is hand-crafted pre-processing that transforms input variables into a new space where the machine learning problem is easier to solve. Deep learning largely eliminates the need for this by learning features directly from data.",
      "tags": [
        "ch01",
        "feature-extraction",
        "history"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-032",
      "front": "What are deep neural networks?",
      "back": "<b>Deep neural networks</b> are networks with many layers of learnable weights. The sub-field of machine learning focusing on such networks is called <b>deep learning</b>.",
      "tags": [
        "ch01",
        "deep-learning",
        "definition"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-033",
      "front": "What role do GPUs play in deep learning?",
      "back": "<b>GPUs (Graphics Processing Units)</b> are specialist processors originally developed for graphics rendering. They are well-suited for training neural networks because units in one layer can be evaluated in parallel, mapping well onto the massive parallelism of GPUs.",
      "tags": [
        "ch01",
        "gpu",
        "hardware"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-034",
      "front": "How did compute requirements for state-of-the-art neural networks change before and after 2012?",
      "back": "<ul><li><b>Before 2012 (perceptron era)</b>: Compute doubled roughly every 2 years (following Moore's law)</li><li><b>After 2012 (deep learning era)</b>: Doubling time reduced to 3.4 months (10x increase per year)</li></ul>",
      "tags": [
        "ch01",
        "compute",
        "history"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-035",
      "front": "What is representation learning?",
      "back": "<b>Representation learning</b> views hidden layers as transforming input data into new representations that are semantically meaningful, creating an easier problem for final layers to solve. These learned representations can be repurposed for related problems via transfer learning.",
      "tags": [
        "ch01",
        "representation-learning",
        "deep-learning"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-01-039",
      "front": "How many neurons and synapses does a human brain contain?",
      "back": "A human brain contains:<br><ul><li>Around <b>90 billion neurons</b></li><li>Each neuron has on average several thousand synapses</li><li>Total of around <b>100 trillion (10^14) synapses</b></li></ul>",
      "tags": [
        "ch01",
        "neuroscience",
        "background"
      ]
    }
  ]
}

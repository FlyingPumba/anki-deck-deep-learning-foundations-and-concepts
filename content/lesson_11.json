{
  "id": "11",
  "title": "Lesson 11: Classical ML Methods",
  "lesson_title": "Classical ML Methods",
  "objectives": [
    "Understand decision trees and their properties",
    "Learn random forests and bagging",
    "Master gradient boosting methods",
    "Understand support vector machines",
    "Learn when to use classical ML vs deep learning"
  ],
  "cards": [
    {
      "uid": "deep-learning-foundations-and-concepts-11-001",
      "front": "What is a decision tree?",
      "back": "A tree-structured model that makes predictions by recursively splitting data based on feature thresholds.<br><br><b>Structure</b>:<ul><li><b>Internal nodes</b>: Test a feature (e.g., age > 30?)</li><li><b>Branches</b>: Outcomes of the test</li><li><b>Leaf nodes</b>: Predictions (class label or value)</li></ul><b>Prediction</b>: Traverse from root to leaf based on input features.<br><br><b>Advantages</b>: Interpretable, handles mixed data types, no feature scaling needed.<br><br><b>Disadvantages</b>: Prone to overfitting, high variance, axis-aligned splits only.",
      "tags": [
        "ch11",
        "decision-tree",
        "fundamentals"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-002",
      "front": "How are decision tree splits chosen?",
      "back": "<b>Goal</b>: Find the split that best separates the classes (or reduces variance for regression).<br><br><b>Classification criteria</b>:<ul><li><b>Gini impurity</b>: \\( G = 1 - \\sum_k p_k^2 \\)<br>Probability of misclassifying a random sample.</li><li><b>Entropy</b>: \\( H = -\\sum_k p_k \\log_2 p_k \\)<br>Information content of the distribution.</li><li><b>Information gain</b>: Reduction in entropy after split.</li></ul><b>Regression</b>: Minimize variance or MSE in resulting nodes.<br><br><b>Process</b>: Greedy search over all features and thresholds.",
      "tags": [
        "ch11",
        "decision-tree",
        "splitting"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-003",
      "front": "What is Gini impurity vs entropy for decision trees?",
      "back": "<b>Gini impurity</b>: \\( G = 1 - \\sum_k p_k^2 \\)<ul><li>Faster to compute (no logarithm)</li><li>Ranges from 0 (pure) to 0.5 (binary, equal split)</li><li>Default in scikit-learn</li></ul><b>Entropy</b>: \\( H = -\\sum_k p_k \\log_2 p_k \\)<ul><li>Information-theoretic interpretation</li><li>Ranges from 0 (pure) to 1 (binary, equal split)</li><li>Slightly more computationally expensive</li></ul><b>In practice</b>: Very similar results. Gini slightly favors larger partitions, entropy slightly favors balanced splits.",
      "tags": [
        "ch11",
        "decision-tree",
        "impurity"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-004",
      "front": "How do you prevent overfitting in decision trees?",
      "back": "<b>Pre-pruning</b> (early stopping):<ul><li><b>max_depth</b>: Limit tree depth</li><li><b>min_samples_split</b>: Minimum samples to split a node</li><li><b>min_samples_leaf</b>: Minimum samples in leaf nodes</li><li><b>max_features</b>: Limit features considered per split</li></ul><b>Post-pruning</b>:<ul><li>Grow full tree, then remove branches</li><li>Cost-complexity pruning (minimize error + \\( \\alpha \\cdot |T| \\))</li><li>Reduced error pruning: Remove if validation error doesn't increase</li></ul><b>Rule of thumb</b>: Start with max_depth=5-10, tune via cross-validation.",
      "tags": [
        "ch11",
        "decision-tree",
        "regularization"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-005",
      "front": "What is a Random Forest?",
      "back": "An ensemble of decision trees trained on <b>bootstrap samples</b> with <b>random feature subsets</b>.<br><br><b>Key ideas</b>:<ol><li><b>Bagging</b>: Each tree trained on random sample with replacement</li><li><b>Feature randomness</b>: Each split considers only \\( \\sqrt{p} \\) random features</li><li><b>Aggregation</b>: Average (regression) or vote (classification)</li></ol><b>Why it works</b>: Decorrelates trees, reducing variance without increasing bias.<br><br><b>Hyperparameters</b>: n_estimators (100-500 typical), max_depth, max_features.",
      "tags": [
        "ch11",
        "random-forest",
        "ensemble"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-006",
      "front": "Why does Random Forest use random feature subsets?",
      "back": "<b>Problem with bagging alone</b>: If one feature is very strong, all trees will split on it first, making trees correlated.<br><br><b>Solution</b>: At each split, only consider a random subset of features.<br><br><b>Typical values</b>:<ul><li>Classification: \\( \\sqrt{p} \\) features</li><li>Regression: \\( p/3 \\) features</li></ul><b>Effect</b>: Trees become less correlated, ensemble averaging is more effective.<br><br><b>Trade-off</b>: Individual trees may be weaker, but the ensemble is stronger.",
      "tags": [
        "ch11",
        "random-forest",
        "decorrelation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-007",
      "front": "What is out-of-bag (OOB) error in Random Forest?",
      "back": "<b>OOB error</b>: A built-in cross-validation estimate using samples not in each tree's bootstrap.<br><br><b>How it works</b>:<ol><li>Each tree is trained on ~63% of data (bootstrap sample)</li><li>Remaining ~37% (out-of-bag) can validate that tree</li><li>For each sample, aggregate predictions from trees where it was OOB</li><li>Compare to true labels</li></ol><b>Advantages</b>:<ul><li>No need for separate validation set</li><li>Computed during training for free</li><li>Good estimate of generalization error</li></ul>",
      "tags": [
        "ch11",
        "random-forest",
        "oob"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-008",
      "front": "What is Gradient Boosting?",
      "back": "An ensemble method that builds trees <b>sequentially</b>, each correcting the errors of the previous.<br><br><b>Key idea</b>: Fit new tree to the <b>residuals</b> (gradient of loss) of current ensemble.<br><br><b>Algorithm</b>:<ol><li>Initialize with constant prediction</li><li>For m = 1 to M:<br>  - Compute residuals (negative gradient)</br>  - Fit tree to residuals<br>  - Add tree to ensemble (with learning rate)</li></ol><b>Loss functions</b>: MSE (regression), log loss (classification), custom.<br><br><b>Implementations</b>: XGBoost, LightGBM, CatBoost.",
      "tags": [
        "ch11",
        "gradient-boosting",
        "ensemble"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-009",
      "front": "What is the difference between bagging and boosting?",
      "back": "<b>Bagging</b> (Random Forest):<ul><li>Trees trained <b>independently in parallel</b></li><li>Each tree on bootstrap sample</li><li>Reduces <b>variance</b></li><li>Less prone to overfitting</li></ul><b>Boosting</b> (XGBoost, AdaBoost):<ul><li>Trees trained <b>sequentially</b></li><li>Each tree corrects previous errors</li><li>Reduces <b>bias</b></li><li>Can overfit if not regularized</li></ul><b>When to use</b>:<ul><li>Bagging: When model has high variance</li><li>Boosting: When model has high bias, or for maximum accuracy</li></ul>",
      "tags": [
        "ch11",
        "ensemble",
        "comparison"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-010",
      "front": "What are the key hyperparameters in XGBoost/LightGBM?",
      "back": "<b>Tree structure</b>:<ul><li><b>max_depth</b>: Tree depth (3-10 typical, lower = less overfit)</li><li><b>num_leaves</b> (LightGBM): Max leaves per tree</li><li><b>min_child_weight</b>: Minimum sum of instance weights in child</li></ul><b>Regularization</b>:<ul><li><b>learning_rate</b>: Shrinkage (0.01-0.3, lower = more trees needed)</li><li><b>n_estimators</b>: Number of trees (use early stopping)</li><li><b>subsample</b>: Fraction of samples per tree</li><li><b>colsample_bytree</b>: Fraction of features per tree</li><li><b>reg_lambda</b> (L2), <b>reg_alpha</b> (L1): Weight regularization</li></ul>",
      "tags": [
        "ch11",
        "gradient-boosting",
        "hyperparameters"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-011",
      "front": "What is the bias-variance tradeoff in ensemble methods?",
      "back": "<b>Single decision tree</b>: Low bias, high variance (overfits easily).<br><br><b>Bagging (Random Forest)</b>:<ul><li>Averaging reduces variance</li><li>Bias stays roughly the same</li><li>Works well when individual trees overfit</li></ul><b>Boosting</b>:<ul><li>Sequential correction reduces bias</li><li>Each tree is simple (low variance individually)</li><li>Ensemble can have lower variance than deep tree</li></ul><b>Key insight</b>: Bagging reduces variance of high-variance models. Boosting reduces bias by combining weak learners.",
      "tags": [
        "ch11",
        "ensemble",
        "bias-variance"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-012",
      "front": "What is a Support Vector Machine (SVM)?",
      "back": "A classifier that finds the <b>maximum-margin hyperplane</b> separating classes.<br><br><b>Key idea</b>: Among all separating hyperplanes, choose the one with the largest distance to the nearest points (support vectors).<br><br><b>Objective</b>:<br>\\( \\min_{w,b} \\frac{1}{2}||w||^2 \\)<br>subject to \\( y_i(w^T x_i + b) \\geq 1 \\)<br><br><b>Support vectors</b>: Points on the margin boundary. Only these affect the decision boundary.<br><br><b>Soft margin</b>: Allow some misclassification with slack variables \\( \\xi_i \\) and penalty C.",
      "tags": [
        "ch11",
        "svm",
        "fundamentals"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-013",
      "front": "What is the kernel trick in SVMs?",
      "back": "<b>Problem</b>: Data may not be linearly separable in original space.<br><br><b>Solution</b>: Map to higher-dimensional space where it is separable.<br><br><b>Kernel trick</b>: Compute dot products in high-D space without explicitly computing the mapping:<br>\\( K(x_i, x_j) = \\phi(x_i)^T \\phi(x_j) \\)<br><br><b>Common kernels</b>:<ul><li><b>Linear</b>: \\( K(x,y) = x^T y \\)</li><li><b>RBF/Gaussian</b>: \\( K(x,y) = \\exp(-\\gamma ||x-y||^2) \\)</li><li><b>Polynomial</b>: \\( K(x,y) = (x^T y + c)^d \\)</li></ul><b>RBF</b> is most common: implicitly maps to infinite-dimensional space.",
      "tags": [
        "ch11",
        "svm",
        "kernel"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-014",
      "front": "What are the key hyperparameters for SVM?",
      "back": "<b>C (regularization)</b>:<ul><li>Small C: Wide margin, more misclassification allowed (underfitting)</li><li>Large C: Narrow margin, fewer misclassifications (overfitting)</li></ul><b>gamma (RBF kernel)</b>:<ul><li>Small gamma: Large radius of influence (smoother boundary)</li><li>Large gamma: Small radius (more complex boundary, overfitting)</li></ul><b>Relationship</b>: C and gamma often need to be tuned together.<br><br><b>Best practice</b>: Grid search over log-scale (e.g., C = [0.001, 0.01, 0.1, 1, 10, 100]).",
      "tags": [
        "ch11",
        "svm",
        "hyperparameters"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-015",
      "front": "When should you use classical ML vs deep learning?",
      "back": "<b>Prefer classical ML (trees, SVMs, linear models)</b>:<ul><li>Small to medium datasets (<100K samples)</li><li>Tabular/structured data</li><li>Interpretability is important</li><li>Limited compute resources</li><li>Need fast training/inference</li></ul><b>Prefer deep learning</b>:<ul><li>Large datasets</li><li>Unstructured data (images, text, audio)</li><li>Spatial/sequential structure matters</li><li>Can leverage pre-trained models</li><li>Have GPU resources</li></ul><b>Rule of thumb</b>: For tabular data, start with gradient boosting (XGBoost/LightGBM). For images/text, start with neural networks.",
      "tags": [
        "ch11",
        "comparison",
        "practical"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-016",
      "front": "What is feature importance in tree-based models?",
      "back": "<b>Methods to measure feature importance</b>:<br><br><b>1. Impurity-based</b>: Sum of impurity decrease across all splits using that feature.<ul><li>Fast, built into training</li><li>Biased toward high-cardinality features</li></ul><b>2. Permutation importance</b>: Shuffle feature values, measure drop in accuracy.<ul><li>Model-agnostic</li><li>More reliable, but slower</li></ul><b>3. SHAP values</b>: Game-theoretic attribution.<ul><li>Most principled</li><li>Provides both global and local importance</li></ul><b>Caution</b>: Importance doesn't imply causation. Correlated features share importance.",
      "tags": [
        "ch11",
        "feature-importance",
        "interpretability"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-017",
      "front": "What is early stopping in gradient boosting?",
      "back": "<b>Early stopping</b>: Stop adding trees when validation performance stops improving.<br><br><b>How it works</b>:<ol><li>Monitor metric on validation set each round</li><li>Stop if no improvement for N rounds (patience)</li><li>Return model with best validation score</li></ol><b>Benefits</b>:<ul><li>Prevents overfitting</li><li>Saves training time</li><li>Automatically determines n_estimators</li></ul><b>Usage</b>:<pre>model.fit(X_train, y_train,<br>  eval_set=[(X_val, y_val)],<br>  early_stopping_rounds=50)</pre>",
      "tags": [
        "ch11",
        "gradient-boosting",
        "regularization"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-018",
      "front": "What is the difference between XGBoost, LightGBM, and CatBoost?",
      "back": "<b>XGBoost</b>:<ul><li>Level-wise tree growth (balanced trees)</li><li>Supports GPU training</li><li>Most mature, widely used</li></ul><b>LightGBM</b>:<ul><li>Leaf-wise tree growth (can be deeper)</li><li>Faster training, lower memory</li><li>Better for large datasets</li><li>Histogram-based splitting</li></ul><b>CatBoost</b>:<ul><li>Native handling of categorical features</li><li>Ordered boosting (reduces prediction shift)</li><li>Often best out-of-the-box performance</li></ul><b>In practice</b>: All three achieve similar accuracy with tuning. LightGBM fastest, CatBoost easiest for categoricals.",
      "tags": [
        "ch11",
        "gradient-boosting",
        "comparison"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-019",
      "front": "What is boosting?",
      "back": "An ensemble method that combines multiple <b>weak classifiers</b> sequentially.<br>Each new classifier focuses on examples the previous ones got wrong.<br>Final prediction is weighted combination.<br>Examples: AdaBoost, Gradient Boosting, XGBoost.",
      "tags": [
        "ch11",
        "boosting",
        "ensemble"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-020",
      "front": "What are committees (ensembles) in machine learning?",
      "back": "Combining predictions from <b>multiple models</b> to improve performance.<br>Methods:<br><ul><li><b>Averaging</b>: Mean of predictions</li><li><b>Voting</b>: Majority vote for classification</li><li><b>Weighted combination</b>: Based on model quality</li></ul>Reduces variance and often improves accuracy.",
      "tags": [
        "ch11",
        "ensemble",
        "committees"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-021",
      "front": "What is bootstrap aggregation (bagging)?",
      "back": "Creating multiple models trained on <b>bootstrap samples</b> of the data.<br>Bootstrap sample: Draw N points <b>with replacement</b> from original N points.<br>Each model sees different subset. Average predictions for final output.<br>Reduces variance without increasing bias.",
      "tags": [
        "ch11",
        "bagging",
        "ensemble"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-022",
      "front": "What is a bootstrap dataset?",
      "back": "A dataset \\( X_B \\) created by drawing N points <b>at random with replacement</b> from original dataset X of N points.<br>Some points appear multiple times, others not at all.<br>On average, ~63.2% of original points appear in each bootstrap sample.",
      "tags": [
        "ch11",
        "bootstrap",
        "sampling"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-023",
      "front": "Why doesn't ensemble averaging reduce error as much as theory suggests?",
      "back": "Theory: Averaging M models reduces error by factor of M.<br>Reality: <b>Errors are typically highly correlated</b> between models.<br>Correlated errors don't cancel out. Reduction is much smaller than 1/M.<br>Diversity among ensemble members is key to improvement.",
      "tags": [
        "ch11",
        "ensemble",
        "correlation"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-024",
      "front": "How does K-nearest neighbors work for classification?",
      "back": "<b>Intuition</b>: \"You are who your friends are.\" To classify a new point, look at its K nearest neighbors and take a vote.<br><b>Example</b>: If K=5 and 3 neighbors are cats, 2 are dogs, classify as cat.<br><b>Choosing K</b>: Small K = sensitive to noise, large K = smoother boundaries but may miss local patterns.<br><b>Downside</b>: Must store all training data and compare against each for every prediction.",
      "tags": [
        "ch11",
        "knn-classification",
        "nonparametric"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-025",
      "front": "What is the naive Bayes model?",
      "back": "A generative model that assumes <b>conditional independence</b> of features given the class.<br><br><b>Intuition</b>: Imagine classifying emails as spam. Naive Bayes assumes that given an email is spam, the presence of the word 'free' is independent of the word 'money' - each word contributes evidence independently. This is 'naive' because words often <i>do</i> correlate, but the simplification works surprisingly well.<br><br><b>Formula</b>: \\( p(\\vec{x}|C_k) = \\prod_i p(x_i|C_k) \\)<br><br><b>Why it works</b>: Even if independence is violated, the model often ranks classes correctly. We only need the <i>most probable</i> class, not accurate probabilities.",
      "tags": [
        "ch11",
        "naive-bayes",
        "generative"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-026",
      "front": "What is outlier detection (novelty detection)?",
      "back": "Identifying inputs that differ significantly from the training data.<br>Important when test data may contain examples from classes not seen during training.<br>Generative models are naturally suited for this since they model \\( p(\\vec{x}) \\).",
      "tags": [
        "ch11",
        "outlier-detection",
        "novelty-detection"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-027",
      "front": "What is model-based machine learning?",
      "back": "An approach where:<br><ol><li><b>Domain knowledge</b> is encoded in model structure</li><li><b>Inductive biases</b> are explicitly designed</li><li>Learning is constrained by the model's assumptions</li></ol>Contrast with purely data-driven approaches. Combines expert knowledge with learning from data.",
      "tags": [
        "ch11",
        "model-based",
        "inductive-bias"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-028",
      "front": "How can averaging help with the bias-variance trade-off?",
      "back": "Averaging predictions from multiple models can reduce variance without increasing bias.<br>This is the basis for <b>ensemble methods</b> like:<br><ul><li>Bagging</li><li>Random forests</li><li>Model averaging</li></ul>Combines multiple high-variance models to get lower variance.",
      "tags": [
        "ch11",
        "ensemble",
        "averaging"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-029",
      "front": "What is SHAP for model interpretability?",
      "back": "<b>SHapley Additive exPlanations</b>: A unified framework for feature attribution based on game theory.<br><br><b>Key idea</b>: Assign each feature an importance value based on Shapley values from cooperative game theory.<br><br><b>Properties</b> (uniquely satisfied):<ul><li><b>Local accuracy</b>: Attributions sum to model output</li><li><b>Missingness</b>: Missing features get zero attribution</li><li><b>Consistency</b>: If a feature's contribution increases, its attribution doesn't decrease</li></ul><b>Variants</b>:<ul><li><b>KernelSHAP</b>: Model-agnostic, uses weighted linear regression</li><li><b>DeepSHAP</b>: Efficient for deep networks</li><li><b>TreeSHAP</b>: Exact and fast for tree-based models</li></ul>",
      "tags": [
        "ch11",
        "shap",
        "interpretability"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-030",
      "front": "What is LIME for model interpretability?",
      "back": "<b>Local Interpretable Model-agnostic Explanations</b>: Explains individual predictions by fitting a simple model locally.<br><br><b>How it works</b>:<ol><li>Generate perturbed samples around the input</li><li>Get model predictions for perturbations</li><li>Fit an interpretable model (e.g., linear) to approximate locally</li><li>Interpret the simple model's coefficients</li></ol><b>For images</b>: Perturbations mask/reveal superpixels.<br><br><b>Advantages</b>:<ul><li>Model-agnostic (works for any classifier)</li><li>Produces human-understandable explanations</li></ul><b>Limitation</b>: Explanations can be unstable (sensitive to perturbation strategy).",
      "tags": [
        "ch11",
        "lime",
        "interpretability"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-031",
      "front": "What is the difference between global and local interpretability?",
      "back": "<b>Global interpretability</b>: Understanding the model's overall behavior.<ul><li>What features matter in general?</li><li>What patterns has the model learned?</li><li>Methods: Feature importance, partial dependence plots</li></ul><b>Local interpretability</b>: Understanding a specific prediction.<ul><li>Why did the model predict this for this input?</li><li>Which features drove this particular decision?</li><li>Methods: LIME, SHAP, Grad-CAM, saliency maps</li></ul><b>Trade-off</b>: Simpler models (linear, trees) are globally interpretable but less accurate. Complex models need post-hoc explanation methods.",
      "tags": [
        "ch11",
        "interpretability",
        "concepts"
      ]
    },
    {
      "uid": "deep-learning-foundations-and-concepts-11-032",
      "front": "What is the difference between causal and predictive modeling?",
      "back": "<b>Predictive modeling</b>: Find \\( P(Y|X) \\) to predict Y from X.<ul><li>Correlation is sufficient</li><li>Spurious correlations can help prediction</li><li>Fails under distribution shift</li></ul><b>Causal modeling</b>: Understand how interventions on X affect Y.<ul><li>Requires \\( P(Y|do(X)) \\), not just \\( P(Y|X) \\)</li><li>Robust to certain distribution shifts</li><li>Enables answering counterfactual questions</li></ul><b>Key distinction</b>: Prediction asks 'what will Y be if I observe X?'. Causation asks 'what will Y be if I <i>set</i> X?'<br><br><b>Testing causality from observational data</b>:<ul><li>Randomized experiments (gold standard)</li><li>Instrumental variables</li><li>Regression discontinuity</li><li>Difference-in-differences</li><li>Causal discovery algorithms (PC, FCI)</li></ul><b>Challenges</b>: Confounders, selection bias, unobserved variables. Observational data alone rarely proves causation without strong assumptions.",
      "tags": [
        "ch11",
        "causality",
        "prediction"
      ]
    }
  ]
}
